import logging
import time
import asyncio
from typing import Dict, Any, Optional, List
from dataclasses import asdict
from langgraph.graph import StateGraph, END

# [Import] State ë° Core ë¡œì§
from backend.agents.recommend.agent.state import RecommendState
from backend.agents.recommend.core.ingest.summarizer import ContentSummarizer
from backend.core.models import RepoSnapshot
# [Import] ê²€ìƒ‰ ì—”ì§„ (ë°©ê¸ˆ ë§Œë“  ì½”ë“œ)
from backend.agents.recommend.core.search.vector_search import vector_search_engine
from backend.agents.recommend.core.analysis.match_score import RepoScorer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(name)s | %(message)s')
logger = logging.getLogger("TestRealAgent")

# ------------------------------------------------------------------
# 1. Global Instances
# ------------------------------------------------------------------
try:
    summarizer_instance = ContentSummarizer()
    scorer_instance = RepoScorer() # Scorer ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ì¬ì‚¬ìš©)
    logger.info("âœ… Global instances initialized.")
except Exception as e:
    logger.error(f"âŒ Failed to init global instances: {e}")
    exit(1)

# ------------------------------------------------------------------
# 2. Nodes Definition
# ------------------------------------------------------------------

def fetch_snapshot_node(state: RecommendState) -> Dict[str, Any]:
    """GitHub ì €ì¥ì†Œ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘"""
    if state.repo_snapshot:
        logger.info("Reusing existing repo snapshot")
        return {"step": state.step + 1} 
    
    owner, repo = state.owner, state.repo
    if not owner or not repo:
        return {"error": "Missing owner/repo", "step": state.step + 1}
    
    from backend.core.github_core import fetch_repo_snapshot
    start_time = time.time()
    
    try:
        snapshot = fetch_repo_snapshot(owner, repo, getattr(state, 'ref', 'main'))
        snapshot_dict = snapshot.model_dump() if hasattr(snapshot, "model_dump") else asdict(snapshot)
        
        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["fetch_snapshot"] = elapsed
        
        logger.info(f"Fetched snapshot for {owner}/{repo} in {elapsed}s")
        return {"repo_snapshot": snapshot_dict, "timings": timings, "step": state.step + 1}
        
    except Exception as e:
        logger.error(f"Failed to fetch snapshot: {e}")
        return {"error": str(e), "failed_step": "fetch_snapshot_node", "step": state.step + 1}

async def analyze_readme_summary_node(state: RecommendState) -> Dict[str, Any]:
    """README ë¶„ì„ ë° ìš”ì•½"""
    if state.readme_summary: return {"step": state.step + 1}
    if not state.repo_snapshot: 
        return {"error": "No snapshot", "failed_step": "analyze_readme_summary_node", "step": state.step + 1}
    
    from backend.core.docs_core import analyze_docs, extract_and_structure_summary_input
    start_time = time.time()
    
    try:
        snapshot_dict = state.repo_snapshot
        readme_content = snapshot_dict.get("readme_content") or "" 
        snapshot_obj = RepoSnapshot(**snapshot_dict)

        docs_result = analyze_docs(snapshot_obj)
        docs_result_dict = asdict(docs_result)
        llm_input_text = extract_and_structure_summary_input(readme_content)

        final_summary = "No summary generated."
        if llm_input_text and len(readme_content) > 50:
            final_summary = await summarizer_instance.summarize(llm_input_text)
            logger.info("LLM summary generated successfully.")
        else:
            logger.warning("Skipping LLM summary: README too short/empty.")

        ingest_result = {
            "final_summary": final_summary,
            "docs_analysis": docs_result_dict,
            "readme_word_count": len(readme_content.split()),
            "documentation_quality": docs_result_dict.get("total_score", 0)
        }

        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["analyze_readme_summary"] = elapsed

        return {"readme_summary": ingest_result, "timings": timings, "step": state.step + 1, "error": None}

    except Exception as e:
        logger.error(f"Failed to analyze README: {e}")
        return {"error": str(e), "failed_step": "analyze_readme_summary_node", "step": state.step + 1}

async def generate_search_query_node(state: RecommendState) -> Dict[str, Any]:
    """RAG ì¿¼ë¦¬ ìƒì„± (Fallback ë¡œì§ í¬í•¨)"""
    from backend.agents.recommend.core.search.rag_query_generator import generate_rag_query_and_filters
    
    start_time = time.time()
    logger.info("ğŸš€ Starting RAG Query Generation")

    # [ì¤‘ìš”] READMEê°€ ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ë§Œ ìˆìœ¼ë©´ ë¶„ì„ ëª¨ë“œ ì§„ì…
    if state.repo_snapshot:
        analyzed_data = {
            "repo_snapshot": state.repo_snapshot,
            "readme_summary": state.readme_summary if state.readme_summary else {}
        }
    else:
        analyzed_data = None


    mode = state.user_intent

    user_input = state.user_request if state.user_request.strip() else "Find similar projects."

    try:
        result = await generate_rag_query_and_filters(user_input, mode, analyzed_data)
        
        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["generate_query"] = elapsed
        
        logger.info(f"âœ… Query Generated ({mode}): {result['query']}")

        return {
            "search_query": result.get("query", ""),
            "search_keywords": result.get("keywords", []),
            "search_filters": result.get("filters", {}),
            "timings": timings,
            "step": state.step + 1,
            "error": None
        }

    except Exception as e:
        logger.error(f"âŒ Failed to generate query: {e}")
        return {"error": str(e), "failed_step": "generate_search_query_node", "step": state.step + 1}

# =================================================================
# ğŸ‘‡ [NEW] 4. Vector Search Node (DB ì¡°íšŒ)
# =================================================================
def vector_search_node(state: RecommendState) -> Dict[str, Any]:
    """ìƒì„±ëœ ì¿¼ë¦¬ë¡œ Qdrant ê²€ìƒ‰ ìˆ˜í–‰"""
    
    # ì• ë‹¨ê³„ì—ì„œ ì¿¼ë¦¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆë‹¤ë©´ ì‹¤í–‰ ë¶ˆê°€
    if not state.search_query:
        logger.warning("No search query found. Skipping vector search.")
        return {"step": state.step + 1}
    
    from backend.agents.recommend.agent.state import RAGCandidateRepo

    start_time = time.time()
    logger.info(f"ğŸ” Executing Vector Search for: '{state.search_query}'")

    try:
        # 1. DB ê²€ìƒ‰ ì‹¤í–‰
        result = vector_search_engine.search(
            query=state.search_query,
            filters=state.search_filters,
            target_k=10
        )
        
        raw_recommendations = result.get("final_recommendations", [])
        
        # 2. [í•µì‹¬] Raw Dict -> RAGCandidateRepo ê°ì²´ë¡œ ë³€í™˜ (Mapping)
        structured_results: List[RAGCandidateRepo] = []
        
        for item in raw_recommendations:
            # Qdrant/FlashRank ê²°ê³¼ì—ì„œ í•„ë“œë¥¼ ë§¤í•‘í•˜ì—¬ ê°ì²´ ìƒì„±
            repo_obj = RAGCandidateRepo(
                id=item.get("project_id"),
                name=item.get("name"),
                owner=item.get("owner"),
                description=item.get("description"),
                stars=int(item.get("stars", 0)),
                forks=int(item.get("forks", 0)),
                main_language=item.get("main_language", "UNKNOWN"),
                languages=item.get("languages") or [],
                topics=item.get("topics") or [],
                html_url=item.get("repo_url") or f"https://github.com/{item.get('owner')}/{item.get('name')}",
                
                # ê²€ìƒ‰ ì—”ì§„ì´ ê³„ì‚°í•œ ì ìˆ˜ì™€ ìŠ¤ë‹ˆí«
                score=item.get("rerank_score", 0.0),
                match_snippet=item.get("match_snippet", ""),
            )
            structured_results.append(repo_obj)
        
        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["vector_search"] = elapsed
        
        logger.info(f"âœ… Found {len(structured_results)} recommendations in {elapsed}s")

        return {
            "search_results": structured_results, # â­ï¸ ì´ì œ ê°ì²´ ë¦¬ìŠ¤íŠ¸ê°€ ì €ì¥ë¨
            "timings": timings,
            "step": state.step + 1,
            "error": None
        }

    except Exception as e:
        logger.error(f"âŒ Vector search failed: {e}")
        return {
            "error": str(e), 
            "failed_step": "vector_search_node", 
            "step": state.step + 1
        }
    
# =================================================================
# ğŸ‘‡ [NEW] 5. Scoring Node (LLM í‰ê°€)
# =================================================================
async def score_candidates_node(state: RecommendState) -> Dict[str, Any]:
    """LLMì„ ì´ìš©í•œ í›„ë³´êµ° ìƒì„¸ í‰ê°€"""
    
    # 1. í‰ê°€í•  í›„ë³´ê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
    if not state.search_results:
        logger.info("No candidates to score. Skipping.")
        return {"step": state.step + 1}

    start_time = time.time()
    logger.info(f"ğŸ§  Scoring {len(state.search_results)} candidates...")

    try:
        # 2. Stateì— ìˆëŠ” Dict í˜•íƒœì˜ Snapshotì„ ê°ì²´ë¡œ ë³µì› (Scorerê°€ ê°ì²´ë¥¼ ìš”êµ¬í•¨)
        source_snapshot = None
        if state.repo_snapshot:
            source_snapshot = RepoSnapshot(**state.repo_snapshot)
        
        # 3. Readme ìš”ì•½ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        readme_summary_text = ""
        if state.readme_summary and isinstance(state.readme_summary, dict):
            readme_summary_text = state.readme_summary.get("final_summary", "")

        # 4. Scorer ì‹¤í–‰
        scored_results = await scorer_instance.evaluate_candidates(
            candidates=state.search_results,     # vector_search ê²°ê³¼
            user_request=state.user_request,
            intent=state.user_intent,            # "semantic_search" or "url_analysis"
            source_repo=source_snapshot,         # ì›ë³¸ ê°ì²´
            readme_summary=readme_summary_text   # ìš”ì•½ë³¸ ìŠ¤íŠ¸ë§
        )

        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["ai_scoring"] = elapsed

        logger.info(f"âœ… Scoring complete. Top 1: {scored_results[0].name} (Score: {scored_results[0].ai_score})")

        return {
            "search_results": scored_results, # ì ìˆ˜ê°€ ë§¤ê²¨ì§„ ë¦¬ìŠ¤íŠ¸ë¡œ ì—…ë°ì´íŠ¸
            "timings": timings,
            "step": state.step + 1,
            "error": None
        }

    except Exception as e:
        logger.error(f"âŒ Scoring failed: {e}")
        # ì—ëŸ¬ê°€ ë‚˜ë„ í”„ë¡œì„¸ìŠ¤ëŠ” ê³„ì† ì§„í–‰ (í‰ê°€ë§Œ ì‹¤íŒ¨)
        return {"error": str(e), "failed_step": "score_candidates_node", "step": state.step + 1}


def check_ingest_error_node(state: RecommendState) -> Dict[str, Any]:
    if not state.error: return {"step": state.step + 1}
    if state.retry_count < state.max_retry:
        return {"error": None, "failed_step": state.failed_step, "retry_count": state.retry_count + 1, "step": state.step + 1}
    return {"step": state.step + 1}

# ------------------------------------------------------------------
# 3. Routing Logic
# ------------------------------------------------------------------

def route_after_fetch(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    return "analyze_readme_summary_node"

def route_after_analysis(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    return "generate_search_query_node"

def route_after_query_gen(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    return "vector_search_node"

def route_after_vector_search(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    # âœ… ê²€ìƒ‰ í›„ -> í‰ê°€(Scoring) ë…¸ë“œë¡œ ì´ë™
    return "score_candidates_node"

def route_after_scoring(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    # âœ… í‰ê°€ ë° ì •ë ¬ ì™„ë£Œ -> ì¢…ë£Œ
    return END

def route_after_error_check(state: RecommendState) -> str:
    if state.error: return END 
    step_map = {
        "fetch_snapshot_node": "fetch_snapshot_node",
        "analyze_readme_summary_node": "analyze_readme_summary_node",
        "generate_search_query_node": "generate_search_query_node",
        "vector_search_node": "vector_search_node",
        "score_candidates_node": "score_candidates_node"
    }
    return step_map.get(state.failed_step, END)

# ------------------------------------------------------------------
# 4. Graph Construction & Execution
# ------------------------------------------------------------------

def build_graph():
    workflow = StateGraph(RecommendState)
    
    # ë…¸ë“œ ë“±ë¡
    workflow.add_node("fetch_snapshot_node", fetch_snapshot_node)
    workflow.add_node("analyze_readme_summary_node", analyze_readme_summary_node)
    workflow.add_node("generate_search_query_node", generate_search_query_node)
    workflow.add_node("vector_search_node", vector_search_node)
    workflow.add_node("score_candidates_node", score_candidates_node) # â­ï¸ ì¶”ê°€ë¨
    workflow.add_node("check_ingest_error_node", check_ingest_error_node)
    
    # ì§„ì…ì 
    workflow.set_entry_point("fetch_snapshot_node")
    
    # ì—£ì§€ ì—°ê²°
    workflow.add_conditional_edges("fetch_snapshot_node", route_after_fetch)
    workflow.add_conditional_edges("analyze_readme_summary_node", route_after_analysis)
    workflow.add_conditional_edges("generate_search_query_node", route_after_query_gen)
    workflow.add_conditional_edges("vector_search_node", route_after_vector_search)
    workflow.add_conditional_edges("score_candidates_node", route_after_scoring) # â­ï¸ ì¶”ê°€ë¨
    workflow.add_conditional_edges("check_ingest_error_node", route_after_error_check)
    
    return workflow.compile()

async def main():
    target_owner = "Hyeri-hci"
    target_repo = "OSSDoctor" 
    
    user_request_scenario = "ì´ í”„ë¡œì íŠ¸ë‘ ê¸°ëŠ¥ì€ ë¹„ìŠ·í•œë°, ì–¸ì–´ëŠ” Pythonìœ¼ë¡œ ëœ í”„ë¡œì íŠ¸ ì°¾ì•„ì¤˜."

    print(f"\n======== ğŸ§ª TESTING REAL AGENT : {target_owner}/{target_repo} ========")
    print(f"ğŸ“ User Request: {user_request_scenario}\n")
    
    graph = build_graph()
    initial_state = RecommendState(
        repo_url=f"https://github.com/{target_owner}/{target_repo}",
        owner=target_owner,
        repo=target_repo,
        user_request=user_request_scenario,
        user_intent="url_analysis" # ì˜ë„ ëª…ì‹œ
    )
    
    final_state = {} 
    
    async for event in graph.astream(initial_state):
        for key, value in event.items():
            print(f" -> Node Completed: {key}")
            final_state.update(value) 

    print("\n======== ğŸ“Š FINAL RESULT ========")
    if final_state:
        # 1. ì¿¼ë¦¬ ë° íƒ€ì´ë° ì •ë³´
        print(f"\nğŸ” [Metadata]")
        print(f" Â  - Query: {final_state.get('search_query')}")
        print(f"ğŸ”¹ Timings: {final_state.get('timings')}")
        
        # 2. ì¶”ì²œ ê²°ê³¼ (AI ì ìˆ˜ í¬í•¨)
        results = final_state.get("search_results", [])
        print(f"\nğŸ† [Recommended Projects] Found: {len(results)}")
        
        for idx, item in enumerate(results, 1):
            print(f" Â  {idx}. {item.name} (â­ {item.stars})")
            print(f" Â  Â  Â - ID: {item.id} | Lang: {item.languages}")
            
            # [NEW] AI ì ìˆ˜ ë° ì‚¬ìœ  ì¶œë ¥
            print(f" Â  Â  Â - ğŸ¤– AI Score: {item.ai_score} / 100")
            print(f" Â  Â  Â - ğŸ“ Reason: {item.ai_reason}")
            
            snippet = item.match_snippet
            clean_snippet = snippet.replace("\n", " ") if snippet else "No snippet"
            print(f" Â  Â  Â - Match: {clean_snippet[:80]}..." if len(clean_snippet) > 80 else f" Â  Â  Â - Match: {clean_snippet}")
            print()
    else:
        print("âŒ Analysis Failed.")

if __name__ == "__main__":
    asyncio.run(main())