import logging
import time
import asyncio
from typing import Dict, Any, Optional
from dataclasses import asdict
from langgraph.graph import StateGraph, END

from backend.agents.recommend.agent.state import RecommendState
from backend.agents.recommend.core.ingest.summarizer import ContentSummarizer
from backend.core.models import RepoSnapshot

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(name)s | %(message)s')
logger = logging.getLogger("TestRealAgent")

# ------------------------------------------------------------------
# 1. Global Instances (LLM ë“± ë¬´ê±°ìš´ ê°ì²´ëŠ” í•œ ë²ˆë§Œ ìƒì„±)
# ------------------------------------------------------------------
try:
    # ì‹¤ì œ API Keyê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ ì‹¤í–‰ë©ë‹ˆë‹¤.
    summarizer_instance = ContentSummarizer()
    logger.info("âœ… ContentSummarizer initialized with Real LLM.")
except Exception as e:
    logger.error(f"âŒ Failed to init ContentSummarizer. Check API Keys: {e}")
    exit(1)

# ------------------------------------------------------------------
# 2. Nodes Definition (ì‚¬ìš©ìë‹˜ì˜ ì‹¤ì œ ë¡œì§ ì ìš©)
# ------------------------------------------------------------------

def fetch_snapshot_node(state: RecommendState) -> Dict[str, Any]:
    """
    GitHub ì €ì¥ì†Œ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ë…¸ë“œ.
    """
    
    # 1. ì¬ì‚¬ìš© ì²´í¬
    if state.repo_snapshot:
        logger.info("Reusing existing repo snapshot")
        return {"step": state.step + 1} 
    
    # 2. í•„ìˆ˜ ì…ë ¥ê°’ ê²€ì¦
    owner = state.owner
    repo = state.repo
    ref = getattr(state, 'ref', 'main') # ref í•„ë“œê°€ ìˆì„ ê²½ìš° ì‚¬ìš©

    # owner, repoê°€ Stateì— ì—†ëŠ” ê²½ìš° ì—ëŸ¬ ì²˜ë¦¬
    if not owner or not repo:
        error_msg = "Owner or repository name is missing in state. (Pre-analysis failure)"
        logger.error(f"Failed to fetch details: {error_msg}")
        return {
            "error": error_msg,
            "failed_step": "fetch_snapshot_node",
            "step": state.step + 1,
        }
    
    from backend.core.github_core import fetch_repo_snapshot

    start_time = time.time()
    
    try:
        
        snapshot = fetch_repo_snapshot(state.owner, state.repo, state.ref)
        
        snapshot_dict = snapshot.model_dump() if hasattr(snapshot, "model_dump") else asdict(snapshot)


        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["fetch_snapshot"] = elapsed
        
        logger.info(f"Fetched snapshot for {state.owner}/{state.repo} in {elapsed}s")
        
        return {
            "repo_snapshot": snapshot_dict,
            "timings": timings,
            "step": state.step + 1,
        }
        
    except Exception as e:
        logger.error(f"Failed to fetch snapshot: {e}")
        return { 
            "error": str(e),
            "failed_step": "fetch_snapshot_node",
            "step": state.step + 1,
        }
    
async def analyze_readme_summary_node(state: RecommendState) -> Dict[str, Any]:
    """
    README ë¶„ì„ ë° LLM ìš”ì•½ ë…¸ë“œ.
    
    repo_snapshotì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ëœ LLM ìš”ì•½ì„ ìƒì„±í•˜ê³  DocsCoreResultë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # 1. ì¬ì‚¬ìš© ì²´í¬ ë° í•„ìˆ˜ ì„ í–‰ ì¡°ê±´ ì²´í¬
    if state.readme_summary:
        logger.info("Reusing existing ingest analysis result")
        return {"step": state.step + 1} 
    
    if not state.repo_snapshot:
        error_msg = "No repo_snapshot available for README analysis."
        logger.error(f"Failed to analyze README: {error_msg}")
        return {
            "error": error_msg,
            "failed_step": "analyze_readme_summary_node",
            "step": state.step + 1,
        }
    
    from backend.core.docs_core import analyze_docs, extract_and_structure_summary_input
    
    start_time = time.time()
    
    try:
        # 2. Stateì—ì„œ ìŠ¤ëƒ…ìƒ· ì¶”ì¶œ
        snapshot_dict = state.repo_snapshot
        readme_content = snapshot_dict.get("readme_content", "")

        # Dict â†’ RepoSnapshot ë³€í™˜
        snapshot_obj = RepoSnapshot(**snapshot_dict)

        # 3. ë¬¸ì„œ ë¶„ì„ (DocsCoreResult dataclass)
        docs_result = analyze_docs(snapshot_obj)

        # dataclass â†’ dict ë³€í™˜
        docs_result_dict = asdict(docs_result)

        # 4. LLM ì…ë ¥ êµ¬ì„±
        llm_input_text = extract_and_structure_summary_input(readme_content)

        # 5. LLM ìš”ì•½ ì‹¤í–‰ (ë¹„ë™ê¸°)
        final_summary = "No summary generated."
        if llm_input_text:
            final_summary = await summarizer_instance.summarize(llm_input_text)
            logger.info("LLM summary generated successfully.")
        else:
            logger.warning("Skipping LLM summary: No structured input generated.")

        # 6. ê²°ê³¼ í†µí•©
        ingest_result = {
            "final_summary": final_summary,
            "docs_analysis": docs_result_dict,   # dictë¡œ ë„£ìŒ
            "readme_word_count": len(readme_content.split()),
            "documentation_quality": docs_result_dict.get("total_score", 0)
        }

        # 7. ìƒíƒœ ì—…ë°ì´íŠ¸ ë°˜í™˜
        elapsed = round(time.time() - start_time, 3)
        timings = dict(state.timings)
        timings["analyze_readme_summary"] = elapsed

        return {
            "readme_summary": ingest_result,
            "timings": timings,
            "step": state.step + 1,
            "failed_step": None,
            "error": None,
        }

    except Exception as e:
        logger.error(f"Failed to analyze and summarize README: {e}")
        return {
            "error": str(e),
            "failed_step": "analyze_readme_summary_node",
            "step": state.step + 1,
        }


def check_ingest_error_node(state: RecommendState) -> Dict[str, Any]:
    """[3ë‹¨ê³„] ì—ëŸ¬ ë³µêµ¬ ë¡œì§"""
    if not state.error:
        return {"step": state.step + 1}
    
    logger.warning(f"âš ï¸ Error caught in step: {state.failed_step}. Retry {state.retry_count}/{state.max_retry}")
    
    if state.retry_count < state.max_retry:
        return {
            "error": None,
            "failed_step": state.failed_step,
            "retry_count": state.retry_count + 1,
            "step": state.step + 1
        }
    
    logger.error("ğŸš« Max retries reached. Giving up.")
    return {"step": state.step + 1} # ì¢…ë£Œ

# ------------------------------------------------------------------
# 3. Routing Logic
# ------------------------------------------------------------------

def route_after_fetch(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    return "analyze_readme_summary_node"

def route_after_analysis(state: RecommendState) -> str:
    if state.error: return "check_ingest_error_node"
    return END

def route_after_error_check(state: RecommendState) -> str:
    if state.error: return END # ë³µêµ¬ ì‹¤íŒ¨
    
    # ì¬ì‹œë„ ë¡œì§
    if state.failed_step == "fetch_snapshot_node":
        return "fetch_snapshot_node"
    elif state.failed_step == "analyze_readme_summary_node":
        return "analyze_readme_summary_node"
    
    return END

# ------------------------------------------------------------------
# 4. Graph Construction & Execution
# ------------------------------------------------------------------

def build_graph():
    workflow = StateGraph(RecommendState)
    
    workflow.add_node("fetch_snapshot_node", fetch_snapshot_node)
    workflow.add_node("analyze_readme_summary_node", analyze_readme_summary_node)
    workflow.add_node("check_ingest_error_node", check_ingest_error_node)
    
    workflow.set_entry_point("fetch_snapshot_node")
    
    workflow.add_conditional_edges("fetch_snapshot_node", route_after_fetch)
    workflow.add_conditional_edges("analyze_readme_summary_node", route_after_analysis)
    workflow.add_conditional_edges("check_ingest_error_node", route_after_error_check)
    
    return workflow.compile()

async def main():
    # ğŸ§ª í…ŒìŠ¤íŠ¸í•  ë¦¬í¬ì§€í† ë¦¬ ì„¤ì • (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë¦¬í¬ì§€í† ë¦¬ì—¬ì•¼ í•¨)
    target_owner = "Hyeri-hci"
    target_repo = "OSSDoctor"
    
    print(f"\n======== ğŸ§ª TESTING REAL AGENT : {target_owner}/{target_repo} ========")
    
    graph = build_graph()
    initial_state = RecommendState(
        repo_url=f"https://github.com/{target_owner}/{target_repo}",
        owner=target_owner,
        repo=target_repo
    )
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    final_state = None
    async for event in graph.astream(initial_state):
        for key, value in event.items():
            print(f" -> Node Completed: {key}")
            final_state = value # ìƒíƒœ ì—…ë°ì´íŠ¸

    print("\n======== ğŸ“Š FINAL RESULT ========")
    if final_state and final_state.get("readme_summary"):
        summary = final_state["readme_summary"]
        print(f"ğŸ”¹ Quality Score: {summary.get('documentation_quality')}")
        print(f"ğŸ”¹ LLM Summary:\n{summary.get('final_summary')}")
        print(f"ğŸ”¹ Timings: {final_state.get('timings')}")
    else:
        print("âŒ Analysis Failed.")
        print(f"Error: {final_state.get('error') if final_state else 'Unknown'}")

if __name__ == "__main__":
    asyncio.run(main())