import json
import os
import asyncio
import argparse
from tqdm.asyncio import tqdm
from typing import List, Dict, Any, Optional

from config.setting import settings
from db.db_check import get_db, TaskType

from adapters.qdrant_client import qdrant_client
from core.qdrant.schemas import RepoSchema, ReadmeSchema 
from qdrant_client.http.models import CollectionStatus

# í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ì„¤ì •
REPO_DESC_MAX_LEN = 2000
README_CONTENT_MAX_LEN = 3000
REPO_NAME_MAX_LEN = 255 

def truncate_string(s: Optional[str], max_len: int) -> str:
    """ë¬¸ìì—´ì„ ì£¼ì–´ì§„ max_lenìœ¼ë¡œ ìë¦…ë‹ˆë‹¤."""
    if s is None:
        return ""
    return str(s)[:max_len]

def transform_to_milvus_data(data: Dict[str, Any]) -> tuple[List[Dict], List[Dict]]:
    """
    JSON í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ Qdrant ì‚½ì…ìš© í˜•ì‹(List[Dict])ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    repo_data = []
    readme_chunks_data = []
    
    # 1. Description/Metadata ë°ì´í„°
    desc_embedding = data.get("description_embedding")
    
    if desc_embedding and isinstance(desc_embedding, list) and isinstance(desc_embedding[0], float):
        repo_item = {
            RepoSchema.FIELD_PROJECT_ID: data.get("project_id"),
            RepoSchema.FIELD_EMBEDDING: desc_embedding,
            RepoSchema.FIELD_NAME: truncate_string(data.get("name"), REPO_NAME_MAX_LEN),
            RepoSchema.FIELD_OWNER: truncate_string(data.get("owner"), REPO_NAME_MAX_LEN),
            RepoSchema.FIELD_REPO_URL: truncate_string(data.get("repo_url"), 512),
            RepoSchema.FIELD_DESC: truncate_string(data.get("description"), REPO_DESC_MAX_LEN),
            RepoSchema.FIELD_MAIN_LANG: data.get("main_language"),
            RepoSchema.FIELD_LICENSE: data.get("license"),
            RepoSchema.FIELD_STARS: data.get("stars", 0),
            RepoSchema.FIELD_FORKS: data.get("forks", 0),
            RepoSchema.FIELD_TOPICS: data.get("topics"), 
            RepoSchema.FIELD_LANGUAGES: data.get("languages"),
        }
        repo_data.append(repo_item)

    # 2. Readme ì²­í¬ ë°ì´í„°
    readme_chunks = data.get("readme_chunks", [])
    readme_embeddings = data.get("readme_embedding", [])
    
    if readme_chunks and readme_embeddings and len(readme_chunks) == len(readme_embeddings):
        project_id = data.get("project_id")
        for idx, (chunk_content, embedding) in enumerate(zip(readme_chunks, readme_embeddings)):
            chunk_item = {
                ReadmeSchema.FIELD_PROJECT_ID: project_id,
                ReadmeSchema.FIELD_CHUNK_IDX: idx,
                ReadmeSchema.FIELD_CONTENT: truncate_string(chunk_content, README_CONTENT_MAX_LEN), 
                ReadmeSchema.FIELD_EMBEDDING: embedding,
            }
            readme_chunks_data.append(chunk_item)

    return repo_data, readme_chunks_data

# =========================================================
# ğŸ¥ Health Monitor (ì„œë²„ ìƒíƒœ ê°ì‹œì) - ë˜í¼ í´ë˜ìŠ¤ ëŒ€ì‘ ìˆ˜ì •ë¨
# =========================================================
async def health_monitor(health_event: asyncio.Event, stop_event: asyncio.Event):
    """
    ì£¼ê¸°ì ìœ¼ë¡œ Qdrant ìƒíƒœë¥¼ ì²´í¬í•˜ì—¬ Greenì¼ ë•Œë§Œ ì‘ì—…ì„ í—ˆìš©í•©ë‹ˆë‹¤.
    """
    check_interval = 2.0  # 2ì´ˆë§ˆë‹¤ ìƒíƒœ ì²´í¬
    print("ğŸ¥ Health Monitor Started...")

    # [ìˆ˜ì • í¬ì¸íŠ¸] ë˜í¼ í´ë˜ìŠ¤ ë‚´ë¶€ì˜ ì‹¤ì œ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì°¾ê¸°
    real_client = qdrant_client
    if hasattr(qdrant_client, "client"):
        real_client = qdrant_client.client
    elif hasattr(qdrant_client, "conn"):  # í˜¹ì‹œ ë³€ìˆ˜ëª…ì´ connì¼ ìˆ˜ë„ ìˆìŒ
        real_client = qdrant_client.conn

    while not stop_event.is_set():
        try:
            # 'readme' ì»¬ë ‰ì…˜ì˜ ìƒíƒœë¥¼ í™•ì¸
            # real_clientë¥¼ ì‚¬ìš©í•˜ì—¬ get_collection í˜¸ì¶œ
            collection_info = await asyncio.to_thread(real_client.get_collection, "repo_readmes")
            status = collection_info.status

            if status == CollectionStatus.GREEN:
                if not health_event.is_set():
                    print(f"\nğŸŸ¢ [Health Monitor] Status is GREEN. Resuming workers...")
                    health_event.set() # ì›Œì»¤ ì§„í–‰ í—ˆìš©
            else:
                # Yellow ë˜ëŠ” Red ìƒíƒœ
                if health_event.is_set():
                    print(f"\nğŸ”´ [Health Monitor] Status is {status}. PAUSING all workers!")
                    health_event.clear() # ì›Œì»¤ ì¼ì‹œ ì •ì§€

        except AttributeError:
            print(f"\nâš ï¸ [Config Error] 'qdrant_client' ë‚´ë¶€ì—ì„œ ì‹¤ì œ QdrantClient ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ‘‰ adapters/qdrant_client.py íŒŒì¼ì—ì„œ ì‹¤ì œ client ê°ì²´ì˜ ë³€ìˆ˜ëª…(ì˜ˆ: self.client)ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            # ì—ëŸ¬ê°€ ë‚˜ë©´ ì¼ë‹¨ ë¬´ì‹œí•˜ê³  ì§„í–‰í• ì§€, ë©ˆì¶œì§€ ê²°ì • (ì—¬ê¸°ì„  ë©ˆì¶¤)
            stop_event.set()
            health_event.clear()
            break

        except Exception as e:
            # ì—°ê²° ì‹¤íŒ¨ ì‹œ ì¼ì‹œ ì •ì§€
            if health_event.is_set():
                print(f"\nâš ï¸ [Health Monitor] Connection Failed ({e}). PAUSING workers...")
                health_event.clear()
        
        await asyncio.sleep(check_interval)

# =========================================================
# ğŸ‘· Worker (ì‘ì—…ì)
# =========================================================
async def worker(worker_id: int, queue: asyncio.Queue, health_event: asyncio.Event, batch_size: int, pbar: tqdm):
    """
    íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤. health_eventê°€ ì¼œì ¸ ìˆì„ ë•Œë§Œ ë™ì‘í•©ë‹ˆë‹¤.
    """
    while True:
        # 1. ê±´ê°• ìƒíƒœ ì²´í¬ (Greenì´ ì•„ë‹ˆë©´ ì—¬ê¸°ì„œ ëŒ€ê¸°)
        await health_event.wait()

        # 2. íì—ì„œ íŒŒì¼ ê²½ë¡œ í•˜ë‚˜ êº¼ë‚´ê¸° (ë¹„ì–´ìˆìœ¼ë©´ ì¢…ë£Œ)
        try:
            file_path = await queue.get()
        except asyncio.QueueEmpty:
            break

        try:
            if not os.path.exists(file_path):
                continue

            filename = os.path.basename(file_path)
            try:
                project_id = int(os.path.splitext(filename)[0])
            except ValueError:
                continue

            # DB ì²˜ë¦¬ ì—¬ë¶€ í™•ì¸
            db = get_db(TaskType.QDRANT_INSERT)
            if db.is_processed(project_id):
                continue

            # 3. ë°ì´í„° ë¡œë“œ
            def load_json_file():
                with open(file_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            
            # ë¡œë“œ ì „ì—ë„ ìƒíƒœ ì²´í¬
            await health_event.wait()
            raw_data = await asyncio.to_thread(load_json_file)
            data = raw_data[0] if isinstance(raw_data, list) and raw_data else raw_data

            repo_data, readme_chunks_data = transform_to_milvus_data(data)
            
            if not repo_data and not readme_chunks_data:
                continue

            # 4. Qdrant ì‚½ì…
            desc_insert_success = True
            readme_insert_success = True
            
            # Repo ë°ì´í„° ì‚½ì…
            await health_event.wait()
            if repo_data:
                try:
                    # insert_dataëŠ” ë˜í¼ í´ë˜ìŠ¤ì˜ ë©”ì†Œë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë³´í†µ êµ¬í˜„ë˜ì–´ ìˆìŒ)
                    await asyncio.to_thread(qdrant_client.insert_data, 'desc', repo_data)
                except Exception as e:
                    # print(f"âŒ [Worker-{worker_id}] DESC Fail: {e}")
                    desc_insert_success = False
            
            # Readme ë°ì´í„° ì‚½ì… (ë°°ì¹˜ ì²˜ë¦¬)
            if readme_chunks_data and desc_insert_success:
                total_chunks = len(readme_chunks_data)
                try:
                    for i in range(0, total_chunks, batch_size):
                        # ë°°ì¹˜ ë£¨í”„ë§ˆë‹¤ ìƒíƒœ í™•ì¸
                        await health_event.wait()
                        
                        batch = readme_chunks_data[i : i + batch_size]
                        await asyncio.to_thread(qdrant_client.insert_data, 'readme', batch)
                        
                except Exception as e:
                    print(f"âŒ [Worker-{worker_id}] README Batch Fail: {e}") 
                    readme_insert_success = False
            
            elif readme_chunks_data and not desc_insert_success:
                readme_insert_success = False

            # 5. ì™„ë£Œ ì²˜ë¦¬
            if desc_insert_success and readme_insert_success:
                db.mark_as_processed(project_id)
            
        except Exception as e:
            print(f"âŒ [Worker-{worker_id}] Unexpected Error: {e}")
        
        finally:
            queue.task_done()
            pbar.update(1)


async def run_qdrant_inserter_smart(target_list=None, max_sessions=10, batch_size=50):
    PROJECT_DATA_DIR = settings.paths.PROJECT_DIR
    
    if not os.path.exists(PROJECT_DATA_DIR):
        print("âŒ ë°ì´í„° í´ë” ì—†ìŒ")
        return

    files = []
    if target_list:
        for f in target_list:
            if not f.endswith(".json"): f += ".json"
            files.append(os.path.join(PROJECT_DATA_DIR, f))
    else:
        files = [
            os.path.join(PROJECT_DATA_DIR, f) 
            for f in os.listdir(PROJECT_DATA_DIR) 
            if f.endswith(".json")
        ]
    
    total_files = len(files)
    if total_files == 0:
        print("â„¹ï¸ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“¥ Smart Qdrant Inserter (Health-Check Enabled)")
    print(f"ğŸ‘‰ íŒŒì¼ ìˆ˜: {total_files}ê°œ")
    print(f"ğŸ‘‰ ì„¤ì •: ì›Œì»¤(ì„¸ì…˜)={max_sessions}, ë°°ì¹˜ í¬ê¸°={batch_size}")

    # 1. í ìƒì„± ë° íŒŒì¼ ì±„ìš°ê¸°
    queue = asyncio.Queue()
    for f in files:
        queue.put_nowait(f)

    # 2. ì œì–´ìš© ì´ë²¤íŠ¸ ìƒì„±
    health_event = asyncio.Event()
    health_event.set() # ì´ˆê¸° ìƒíƒœëŠ” ì§„í–‰ í—ˆìš©
    
    stop_monitor_event = asyncio.Event() 

    # 3. ì§„í–‰ë¥  ë°” ìƒì„±
    pbar = tqdm(total=total_files, desc="Processing")

    # 4. ëª¨ë‹ˆí„° íƒœìŠ¤í¬ ì‹œì‘
    monitor_task = asyncio.create_task(health_monitor(health_event, stop_monitor_event))

    # 5. ì›Œì»¤ íƒœìŠ¤í¬ ì‹œì‘
    workers = []
    for i in range(max_sessions):
        worker_task = asyncio.create_task(
            worker(i, queue, health_event, batch_size, pbar)
        )
        workers.append(worker_task)

    # 6. ëª¨ë“  í ì‘ì—…ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
    await queue.join()

    # 7. ì¢…ë£Œ ì²˜ë¦¬
    for w in workers:
        w.cancel()
    
    stop_monitor_event.set()
    try:
        await monitor_task
    except asyncio.CancelledError:
        pass
    
    pbar.close()
    print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì•ˆì „í•˜ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    parser = argparse.ArgumentParser(description="Qdrant Smart Data Inserter")
    parser.add_argument("--sessions", type=int, default=10, help="ë™ì‹œ ì‹¤í–‰ ì›Œì»¤ ìˆ˜")
    parser.add_argument("--batch", type=int, default=50, help="ë°ì´í„° ì‚½ì… ë°°ì¹˜ ì‚¬ì´ì¦ˆ")
    args = parser.parse_args()

    # ìœˆë„ìš° í™˜ê²½ asyncio ì •ì±… ì„¤ì •
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    try:
        asyncio.run(run_qdrant_inserter_smart(
            target_list=None, 
            max_sessions=args.sessions, 
            batch_size=args.batch
        ))
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ê°•ì œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()