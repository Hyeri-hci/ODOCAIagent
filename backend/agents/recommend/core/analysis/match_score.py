import asyncio
import json
import logging
from typing import List, Dict, Any, Optional

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from backend.agents.recommend.config.setting import settings
from backend.core.models import RepoSnapshot
from backend.agents.recommend.agent.state import CandidateRepo

logger = logging.getLogger("RepoScorer")

# ==============================================================================
# 1. ë‹¨ì¼ í•­ëª© í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ (Single Item Prompts)
# ==============================================================================

# (A) íƒìƒ‰ ëª¨ë“œ: ì´ í”„ë¡œì íŠ¸ê°€ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ”ê°€?
SINGLE_SEMANTIC_PROMPT = """
ë‹¹ì‹ ì€ 'ì†Œí”„íŠ¸ì›¨ì–´ ì†”ë£¨ì…˜ ì•„í‚¤í…íŠ¸'ì…ë‹ˆë‹¤.
ì œì‹œëœ GitHub ë¦¬í¬ì§€í† ë¦¬(Candidate)ê°€ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­(User Request)ì„ ì–¼ë§ˆë‚˜ ì™„ë²½í•˜ê²Œ ì¶©ì¡±í•˜ëŠ”ì§€ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”.

[ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­]
"{user_request}"

[ë¶„ì„ ëŒ€ìƒ í”„ë¡œì íŠ¸ (Candidate)]
- ì €ì¥ì†Œ: {repository}
- ì£¼ì–¸ì–´: {main_language}
- ì‚¬ìš© ì–¸ì–´: {languages}
- ì„¤ëª…: {description}
- í† í”½: {topics}
- Stars: {stars}
- Forks: {forks}
- ë§¤ì¹­ ê·¼ê±°(Snippet): {match_snippet}

[ì§€ì‹œì‚¬í•­]
1. **í‰ê°€ ê¸°ì¤€**:
   - ì›ë³¸ì˜ Readmeë‚˜ ì„¤ëª…ì´ ì¶©ë¶„í•˜ë‹¤ë©´ **ê¸°ëŠ¥ì  ìœ ì‚¬ì„±**ì„ ìµœìš°ì„ ìœ¼ë¡œ ë³´ì„¸ìš”.
   - **(ì¤‘ìš”) ì›ë³¸ ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°(Readme ì—†ìŒ ë“±)**: 
     - **í”„ë¡œì íŠ¸ ì´ë¦„(Repository Name)**ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„± (ì˜ˆ: 'Agent', 'Framework' ë“± í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€)
     - **í† í”½(Topics)**ì˜ ì¼ì¹˜ ì—¬ë¶€
     - ìœ„ ë‘ ê°€ì§€ ë©”íƒ€ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ì„¸ìš”.

2. **ì ìˆ˜(ai_score) ì°¨ë³„í™”**:
   - ëª¨ë“  í›„ë³´ì—ê²Œ ë¹„ìŠ·í•œ ì ìˆ˜ë¥¼ ì£¼ì§€ ë§ˆì„¸ìš”. 
   - ì´ë¦„ì´ë‚˜ í† í”½ì´ ì›ë³¸ê³¼ ë” ì§ê´€ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” í”„ë¡œì íŠ¸ì— ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.

3. **ì´ìœ (ai_reason) ì„œìˆ **:
   - ì›ë³¸ ì •ë³´ê°€ ì—†ì„ ë•ŒëŠ” "ì›ë³¸ ì„¤ëª…ì´ ë¶€ì¡±í•˜ì§€ë§Œ, **í”„ë¡œì íŠ¸ ì´ë¦„ì´ '~'ë¡œ ìœ ì‚¬í•˜ê³ **, **í† í”½ '~'ê°€ ì¼ì¹˜í•˜ì—¬** ëŒ€ì²´ ê°€ëŠ¥ì„±ì´ ë†’ìŒ"ê³¼ ê°™ì´ **ì´ë¦„/í† í”½ ë§¤ì¹­**ì„ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.

4. ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
{{
  "ai_score": 85,
  "ai_reason": "ì‚¬ìš©ìê°€ ìš”êµ¬í•œ Python í™˜ê²½ì„ ì§€ì›í•˜ë©°, RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì— í•„ìš”í•œ ëª¨ë“ˆì„±ì„ ê°–ì¶”ê³  ìˆìŒ."
}}
"""

# (B) ë¹„êµ ëª¨ë“œ: ì´ í”„ë¡œì íŠ¸ê°€ ì›ë³¸ê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•˜ê³  ëŒ€ì²´ ê°€ëŠ¥í•œê°€?
SINGLE_COMPARISON_PROMPT = """
ë‹¹ì‹ ì€ 'ìœ ì‚¬ë„ ë¶„ì„ AI'ì…ë‹ˆë‹¤.
'í›„ë³´ í”„ë¡œì íŠ¸(Candidate)'ê°€ 'ì›ë³¸ í”„ë¡œì íŠ¸(Source)'ì˜ **ê¸°ëŠ¥ê³¼ ì—­í• ì„ ì–¼ë§ˆë‚˜ ì˜ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ”ì§€** í‰ê°€í•˜ì„¸ìš”.

[ì›ë³¸ í”„ë¡œì íŠ¸ ì •ë³´]
{source_context}

[ì‚¬ìš©ì ì œì•½ì¡°ê±´]
"{user_request}"

[ë¶„ì„ ëŒ€ìƒ í”„ë¡œì íŠ¸ (Candidate)]
- ì €ì¥ì†Œ: {repository}
- ì£¼ì–¸ì–´: {main_language}
- ì‚¬ìš© ì–¸ì–´: {languages}
- ì„¤ëª…: {description}
- í† í”½: {topics}
- **í•µì‹¬ ë‚´ìš©**: {match_snippet}

[ë¶„ì„ ë° ì±„ì  ê°€ì´ë“œ]

1. **ì–¸ì–´ í•„í„°ë§ (Language Filter)**:
   - í›„ë³´ì˜ [ì‚¬ìš© ì–¸ì–´ ëª©ë¡]ì— ì‚¬ìš©ì ìš”êµ¬ ì–¸ì–´(ì˜ˆ: Python)ê°€ ì—†ë‹¤ë©´? -> **0ì **.

2. **ì½˜í…ì¸  ê¸°ë°˜ ìœ ì‚¬ë„ í‰ê°€ (Content-Based Matching)**:
   - **í”„ë¡œì íŠ¸ ì´ë¦„ë³´ë‹¤ [í•µì‹¬ ë‚´ìš©(Snippet)]ê³¼ [ì„¤ëª…]ì´ ë” ì¤‘ìš”í•©ë‹ˆë‹¤.**
   - ì›ë³¸ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ê¸°ëŠ¥(ì˜ˆ: Agent, Orchestration, ë¶„ì„ ë„êµ¬ ë“±)ì´ í›„ë³´ í”„ë¡œì íŠ¸ì˜ **í…ìŠ¤íŠ¸ ì„¤ëª…** ì†ì— ë‚˜íƒ€ë‚©ë‹ˆê¹Œ?
   - ì˜ˆ: ì´ë¦„ì´ 'My-Tool'ì´ë¼ë„, ì„¤ëª…ì— "A framework for managing AI Agents"ë¼ê³  ë˜ì–´ ìˆë‹¤ë©´ ìœ ì‚¬í•œ ê²ƒì…ë‹ˆë‹¤.

3. **ìŠ¤íŒ¸ í•„í„° (Context Check)**:
   - ì„¤ëª…ì´ë‚˜ ìŠ¤ë‹ˆí«ì„ ì½ì—ˆì„ ë•Œ, ë‹¨ìˆœí•œ 'ê°•ì˜ ìë£Œ(Course)', 'ë§í¬ ëª¨ìŒ(List/Awesome)', 'ì±…(Book)'ì¸ê°€ìš”?
   - ê·¸ë ‡ë‹¤ë©´ ê¸°ëŠ¥ì  ëŒ€ì²´ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ **30ì  ì´í•˜**ë¡œ ê°ì í•˜ì„¸ìš”.

4. **ì ìˆ˜ ì‚°ì •**:
   - **90~100ì **: ì–¸ì–´ ì¼ì¹˜ + ì„¤ëª…/ìŠ¤ë‹ˆí«ì—ì„œ ì›ë³¸ê³¼ ë™ì¼í•œ í•µì‹¬ ê¸°ëŠ¥(í‚¤ì›Œë“œ)ì´ í™•ì¸ë¨.
   - **70~89ì **: ìœ ì‚¬í•œ ë„ë©”ì¸ì´ì§€ë§Œ, ì„¤ëª…ì´ ì•½ê°„ ëª¨í˜¸í•˜ê±°ë‚˜ ë¶€ê°€ ê¸°ëŠ¥ì´ ë‹¤ë¦„.
   - **0~40ì **: ì–¸ì–´ ë¶ˆì¼ì¹˜ ë˜ëŠ” ë‹¨ìˆœ ìë£Œ ëª¨ìŒì§‘, ì „í˜€ ë‹¤ë¥¸ ê¸°ëŠ¥.

[ì§€ì‹œì‚¬í•­]
- ì´ìœ (ai_reason) ì‘ì„± ì‹œ, "ìŠ¤íƒ€ ìˆ˜ê°€ ì ì–´ì„œ" ê°™ì€ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”.
- ì˜¤ì§ "ê¸°ëŠ¥", "ì´ë¦„ì˜ ìœ ì‚¬ì„±", "í† í”½ì˜ ì¼ì¹˜"ë¥¼ ê·¼ê±°ë¡œ ë“œì„¸ìš”.

[ì‘ë‹µ í˜•ì‹ (JSON)]
{{
  "ai_score": 88,
  "ai_reason": "ì‚¬ìš©ì ìš”êµ¬ ì–¸ì–´(Python)ë¥¼ ë§Œì¡±í•˜ë©°, ì›ë³¸ê³¼ í›„ë³´ ëª¨ë‘ í”„ë¡œì íŠ¸ ì´ë¦„ì— 'Agent'ê°€ í¬í•¨ë˜ì–´ ìˆê³  'LLM' í† í”½ì„ ê³µìœ í•˜ë¯€ë¡œ ê¸°ëŠ¥ì  ëª©ì ì´ ë™ì¼í•  ê²ƒìœ¼ë¡œ íŒë‹¨ë¨."
}}
"""

# ==============================================================================
# 2. Core Class (Parallel Execution)
# ==============================================================================

class RepoScorer:
    def __init__(self):
        self.llm = ChatOpenAI(
            base_url=settings.llm.api_base,
            api_key=settings.llm.api_key,
            model=settings.llm.model_name,
            temperature=0
        )
        self.parser = JsonOutputParser()

    def _format_snapshot(self, snapshot: RepoSnapshot, readme_summary: str) -> str:
        """
        [Helper] Snapshot ê°ì²´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
        ReadmeëŠ” ì´ë¯¸ ìš”ì•½ë˜ì–´ ë“¤ì–´ì™”ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
        """
        return f"""- Repository: {snapshot.full_name}
- Description: {snapshot.description}
- Stars: {snapshot.stars}
- Forks: {snapshot.forks}
- Primary Language: {snapshot.primary_language}
- Readme (Summary):
{readme_summary}
"""
    async def _evaluate_single_repo(
        self, 
        repo: CandidateRepo, 
        user_request: str, 
        intent: str, 
        source_repo: Optional[RepoSnapshot],
        readme_summary: str
    ) -> CandidateRepo:
        """
        [ë‚´ë¶€ í•¨ìˆ˜] ë¦¬í¬ì§€í† ë¦¬ 1ê°œë¥¼ ê°œë³„ì ìœ¼ë¡œ í‰ê°€ (ë¹„ë™ê¸° ë‹¨ìœ„ ì‘ì—…)
        """
        try:
            # 1. ìƒì„¸ ì •ë³´ í¬ë§·íŒ…
            repo_data = {
                "repository": f"{repo.owner}/{repo.name}",
                "main_language": repo.main_language,
                "languages": repo.languages,
                "description": repo.description,
                "topics": ", ".join(repo.topics) if repo.topics else "ì—†ìŒ",
                "stars": repo.stars,
                "forks": repo.forks,
                "match_snippet": repo.match_snippet
            }

            # 2. ëª¨ë“œì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            if intent == "semantic_search":
                prompt = ChatPromptTemplate.from_template(SINGLE_SEMANTIC_PROMPT)
                inputs = {
                    "user_request": user_request,
                    **repo_data
                }
            else:
                # url_analysis ëª¨ë“œì¼ ë•Œ Snapshot ê°ì²´ í¬ë§·íŒ…
                if source_repo:
                    source_context_str = self._format_snapshot(source_repo, readme_summary)
                else:
                    source_context_str = "ì›ë³¸ í”„ë¡œì íŠ¸ ì •ë³´ ì—†ìŒ"

                prompt = ChatPromptTemplate.from_template(SINGLE_COMPARISON_PROMPT)
                inputs = {
                    "source_context": source_context_str,
                    "user_request": user_request,
                    **repo_data
                }

            # 3. LLM í˜¸ì¶œ
            chain = prompt | self.llm | self.parser
            result = await chain.ainvoke(inputs)

            # 4. ê²°ê³¼ ë°˜ì˜
            repo.ai_score = int(result.get("ai_score", 0))
            repo.ai_reason = result.get("ai_reason", "ì´ìœ  ì—†ìŒ")
            
            return repo

        except Exception as e:
            logger.error(f"âŒ Failed to score repo '{repo.name}': {e}")
            repo.ai_score = 0
            repo.ai_reason = f"í‰ê°€ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}"
            return repo

    async def evaluate_candidates(
        self, 
        candidates: List[CandidateRepo], 
        user_request: str, 
        intent: str, 
        source_repo: Optional[RepoSnapshot] = None,
        readme_summary: str = ""
    ) -> List[CandidateRepo]:
        
        if not candidates:
            return []
        
        # 1. Task ë¦¬ìŠ¤íŠ¸ ìƒì„±
        # source_repo(Snapshot ê°ì²´)ë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê¹ë‹ˆë‹¤.
        tasks = [
            self._evaluate_single_repo(repo, user_request, intent, source_repo, readme_summary)
            for repo in candidates
        ]
        
        logger.info(f"ğŸš€ Launching {len(tasks)} parallel scoring tasks (Mode: {intent})...")

        # 2. ë³‘ë ¬ ì‹¤í–‰
        scored_candidates = await asyncio.gather(*tasks)

        # 3. ì •ë ¬ ë° ë°˜í™˜
        results_list = list(scored_candidates)
        results_list.sort(key=lambda x: x.ai_score, reverse=True)
        
        return results_list