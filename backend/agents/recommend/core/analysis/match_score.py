import asyncio
import json
import logging
from typing import List, Dict, Any, Optional

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from backend.agents.recommend.config.setting import settings
from backend.core.models import RepoSnapshot
from backend.agents.recommend.agent.state import CandidateRepo

logger = logging.getLogger("RepoScorer")


# ======================================================================
# 1) PROMPTS
# ======================================================================

SINGLE_SEMANTIC_PROMPT = """
ë‹¹ì‹ ì€ 'ì†Œí”„íŠ¸ì›¨ì–´ ì†”ë£¨ì…˜ ì•„í‚¤í…íŠ¸'ìž…ë‹ˆë‹¤.
ì•„ëž˜ ì •ë³´ëŠ” ì´ í”„ë¡œì íŠ¸ê°€ ì¶”ì²œ í›„ë³´ë¡œ ì„ íƒëœ **í™•ì •ëœ ì´ìœ **ìž…ë‹ˆë‹¤.  
ë”°ë¼ì„œ ì´ë¥¼ ë¶€ì •í•˜ê±°ë‚˜ ìž¬í‰ê°€í•˜ê±°ë‚˜ ì˜ì‹¬í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ê°„ì ‘ì ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

[ì‚¬ìš©ìž ìš”ì²­ ì˜ë„]
"{user_request}"

[ê²€ìƒ‰ ê¸°ë°˜ ë§¤ì¹­ ì •ë³´(í™•ì •)]
- ê²€ìƒ‰ ì¿¼ë¦¬(Search Query): {search_query}
- RAG Query: {rag_query}
- RAG Filters: {rag_filters}

ìœ„ ì¡°ê±´ë“¤ì€ ì´ë¯¸ ì‹œìŠ¤í…œì ìœ¼ë¡œ ì¶©ì¡±ë˜ì—ˆìœ¼ë©°,  
ë‹¹ì‹ ì€ Candidateê°€ ì™œ ì‚¬ìš©ìž ìš”êµ¬ì— ìž˜ ë§žëŠ”ì§€ **ê¸ì •ì  ì´ìœ ë§Œ** ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶„ì„ ëŒ€ìƒ í”„ë¡œì íŠ¸]
- ì €ìž¥ì†Œ: {repository}
- ì£¼ì–¸ì–´: {main_language}
- ì‚¬ìš© ì–¸ì–´: {languages}
- ì„¤ëª…: {description}
- í† í”½: {topics}
- Stars: {stars}
- Forks: {forks}
- ë§¤ì¹­ ê·¼ê±°(Snippet): {match_snippet}

[ì§€ì‹œì‚¬í•­]
1. ì ìˆ˜ëŠ” ì ˆëŒ€ ì£¼ì§€ ë§ˆì„¸ìš”.
2. ë¶€ì¡±í•œ ì •ë³´ê°€ ìžˆì–´ë„ ê¸ì •ì ìœ¼ë¡œ ìœ ì¶”í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
3. ê²€ìƒ‰ ì¡°ê±´ì„ ê¸°ë°˜ìœ¼ë¡œ â€œì™œ ì„ íƒë  ìˆ˜ ìžˆì—ˆëŠ”ì§€â€ë¥¼ ìžì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•´ ì£¼ì„¸ìš”.
4. ì¶œë ¥ì€ JSON ê°ì²´ í•˜ë‚˜ë§Œ.

[ì¶œë ¥ í˜•ì‹(JSON)]
{{
  "ai_reason": string
}}

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""


SINGLE_COMPARISON_PROMPT = """
ë‹¹ì‹ ì€ 'ìœ ì‚¬ë„ ë¶„ì„ AI'ìž…ë‹ˆë‹¤.
ì•„ëž˜ ì •ë³´ëŠ” í›„ë³´ê°€ ì‚¬ìš©ìž ìš”ì²­ í”„ë¡œì íŠ¸ì™€ ê¸°ìˆ ì ìœ¼ë¡œ ìœ ì‚¬í•˜ê±°ë‚˜ ëŒ€ì²´ ê°€ëŠ¥í•˜ë‹¤ê³  íŒë‹¨ëœ  
**ê²€ìƒ‰ ê¸°ë°˜ í™•ì • ì¡°ê±´**ìž…ë‹ˆë‹¤.  
ë”°ë¼ì„œ ì¡´ìž¬ ì—¬ë¶€, ì–¸ì–´ ì—¬ë¶€ ë“±ì„ ë‹¤ì‹œ íŒë‹¨í•˜ê±°ë‚˜ ë¶€ì •í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ê°„ì ‘ì ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

[ì‚¬ìš©ìž ìš”ì²­ ì˜ë„]
"{user_request}"

[ê²€ìƒ‰ ê¸°ë°˜ ë§¤ì¹­ ì •ë³´(í™•ì •)]
- ê²€ìƒ‰ ì¿¼ë¦¬(Search Query): {search_query}
- RAG Query: {rag_query}
- RAG Filters: {rag_filters}

[ì›ë³¸ í”„ë¡œì íŠ¸ ì •ë³´]
{source_context}

[ë¶„ì„ ëŒ€ìƒ í”„ë¡œì íŠ¸]
- ì €ìž¥ì†Œ: {repository}
- ì£¼ì–¸ì–´: {main_language}
- ì‚¬ìš© ì–¸ì–´: {languages}
- ì„¤ëª…: {description}
- í† í”½: {topics}
- í•µì‹¬ ë‚´ìš©: {match_snippet}

[ì§€ì‹œì‚¬í•­]
- ì ìˆ˜ ì ˆëŒ€ ê¸ˆì§€.
- ê¸°ëŠ¥ì  ìœ ì‚¬ì„±, ê¸°ìˆ  ìŠ¤íƒ í˜¸í™˜ì„±, í™•ìž¥ ê°€ëŠ¥ì„± ë“±ì„ **ê¸ì •ì  ì´ìœ ë¡œë§Œ** ìž‘ì„±.
- JSON ê°ì²´ë§Œ ì¶œë ¥.

[ì¶œë ¥ í˜•ì‹(JSON)]
{{
  "ai_reason": string
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""


# ======================================================================
# 2) RepoScorer
# ======================================================================

class RepoScorer:
    def __init__(self):
        self.llm = ChatOpenAI(
            base_url=settings.llm.api_base,
            api_key=settings.llm.api_key,
            model=settings.llm.model_name,
            temperature=0
        )
        self.parser = JsonOutputParser()

    def _format_snapshot(self, snapshot: RepoSnapshot, readme_summary: str) -> str:
        return f"""- Repository: {snapshot.full_name}
- Description: {snapshot.description}
- Stars: {snapshot.stars}
- Forks: {snapshot.forks}
- Primary Language: {snapshot.primary_language}
- Readme (Summary):
{readme_summary}
"""

    async def _evaluate_single_repo(
        self, 
        repo: CandidateRepo, 
        user_request: str, 
        intent: str, 
        source_repo: Optional[RepoSnapshot],
        readme_summary: str
    ) -> CandidateRepo:

        try:
            # rag_filtersëŠ” dictì¼ ê°€ëŠ¥ì„± â†’ promptì— ë“¤ì–´ê°€ê¸° ì „ì— ë¬¸ìžì—´ë¡œ
            rag_filters_str = json.dumps(repo.rag_filters, ensure_ascii=False) \
                if isinstance(repo.rag_filters, dict) else str(repo.rag_filters)

            repo_data = {
                "repository": f"{repo.owner}/{repo.name}",
                "main_language": repo.main_language,
                "languages": repo.languages,
                "description": repo.description,
                "topics": ", ".join(repo.topics) if repo.topics else "ì—†ìŒ",
                "stars": repo.stars,
                "forks": repo.forks,
                "match_snippet": repo.match_snippet,
                "search_query": repo.search_query or "",
                "rag_query": repo.rag_query or "",
                "rag_filters": rag_filters_str,
            }

            if intent == "semantic_search":
                prompt = ChatPromptTemplate.from_template(SINGLE_SEMANTIC_PROMPT)
                inputs = {"user_request": user_request, **repo_data}

            else:
                source_context_str = (
                    self._format_snapshot(source_repo, readme_summary)
                    if source_repo else "ì›ë³¸ í”„ë¡œì íŠ¸ ì •ë³´ ì—†ìŒ"
                )
                prompt = ChatPromptTemplate.from_template(SINGLE_COMPARISON_PROMPT)
                inputs = {
                    "source_context": source_context_str,
                    "user_request": user_request,
                    **repo_data
                }

            chain = prompt | self.llm | self.parser
            result = await chain.ainvoke(inputs)

            repo.ai_reason = result.get("ai_reason", "ì´ìœ  ì—†ìŒ")

            return repo

        except Exception as e:
            logger.error(f"âŒ Failed to score repo '{repo.name}': {e}")
            repo.ai_reason = f"í‰ê°€ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}"
            return repo

    async def evaluate_candidates(
        self, 
        candidates: List[CandidateRepo], 
        user_request: str, 
        intent: str, 
        source_repo: Optional[RepoSnapshot] = None,
        readme_summary: str = ""
    ) -> List[CandidateRepo]:

        if not candidates:
            return []
        
        tasks = [
            self._evaluate_single_repo(repo, user_request, intent, source_repo, readme_summary)
            for repo in candidates
        ]

        logger.info(f"ðŸš€ Launching {len(tasks)} parallel scoring tasks (Mode: {intent})")

        scored_candidates = await asyncio.gather(*tasks)
        return list(scored_candidates)
