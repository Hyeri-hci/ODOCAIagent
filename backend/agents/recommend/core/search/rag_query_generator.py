import json
import logging
from typing import Dict, Any, Literal
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from backend.agents.recommend.config.setting import settings

logger = logging.getLogger(__name__)

try:
    llm = ChatOpenAI(
        base_url=settings.llm.api_base,
        api_key=settings.llm.api_key,
        model=settings.llm.model_name,
        temperature=0
    )
except Exception as e:
    logger.error(f"RAG Query Gen LLM Initialization Failed: {e}")
    raise e

# ==========================================
# 1. ì¼ë°˜ ê²€ìƒ‰ìš© í”„ë¡¬í”„íŠ¸ (URL ì—†ìŒ)
# ==========================================
basic_search_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ë‹¹ì‹ ì€ GitHub RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ DB ì¡°íšŒë¥¼ ìœ„í•œ `query`, `keywords`, `filters`ë¥¼ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.

    ### ì…ë ¥ ë°ì´í„°
    - ìš”ì²­: {user_request}

    ### ê·œì¹™
    1. **Query**: 
       - ì‚¬ìš©ìê°€ ì°¾ê³ ì í•˜ëŠ” **í•µì‹¬ ê¸°ìˆ /ì£¼ì œ**ë¥¼ ì˜ì–´ë¡œ ë³€í™˜í•˜ì„¸ìš”.
       - "ì¶”ì²œí•´ì¤˜", "ì°¾ì•„ì¤˜" ê°™ì€ ìš”ì²­ ë™ì‚¬ëŠ” ì œê±°í•˜ê³  **ê¸°ìˆ  í‚¤ì›Œë“œë§Œ** ì¶”ì¶œí•˜ì„¸ìš”.
       - ì˜ˆ: "ììœ¨ì£¼í–‰ ë”¥ëŸ¬ë‹ ì¶”ì²œí•´ì¤˜" â†’ "autonomous driving deep learning"
       - ì˜ˆ: "ë¨¸ì‹ ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ ì°¾ì•„ì¤˜" â†’ "machine learning framework"
       - **ì ˆëŒ€ "similar projects", "recommendation" ê°™ì€ ë©”íƒ€ í‘œí˜„ì„ ì¿¼ë¦¬ì— ë„£ì§€ ë§ˆì„¸ìš”!**
       
    2. **Keywords**: í•µì‹¬ ê¸°ìˆ  ëª…ì‚¬ 1~3ê°œ (ì˜ì–´).
       - ì˜ˆ: ["autonomous driving", "deep learning", "self-driving"]
       
    3. **Filters**: ì‚¬ìš©ìê°€ **ëª…ì‹œì **ìœ¼ë¡œ ì–¸ì–´, ìŠ¤íƒ€ ìˆ˜, í† í”½ì„ ì–¸ê¸‰í•œ ê²½ìš°ì—ë§Œ í¬í•¨. (ì¶”ì¸¡ ê¸ˆì§€)

    ### ì¶œë ¥ í˜•ì‹ (JSON Only)
    {{
        "query": "string (ê¸°ìˆ  í‚¤ì›Œë“œë§Œ, ë©”íƒ€ í‘œí˜„ ê¸ˆì§€)",
        "keywords": ["str", "str"],
        "filters": {{ "language": "str", "topics": ["str"] }}
    }}
    """),
    ("user", "{user_request}")
])

# ==========================================
# 2. ìœ ì‚¬ë„/ë§¥ë½ ê¸°ë°˜ ê²€ìƒ‰ìš© í”„ë¡¬í”„íŠ¸ (URL ë¶„ì„ ë°ì´í„° í¬í•¨)
# ==========================================
# [ìˆ˜ì •ë¨] ì¶”ë¡ (Inference) ê´€ë ¨ ì§€ì¹¨ ì¶”ê°€
similarity_search_prompt = ChatPromptTemplate.from_messages([
    ("system", """
    ë‹¹ì‹ ì€ 'GitHub í”„ë¡œì íŠ¸ ì¶”ì²œ ì‹œìŠ¤í…œ'ì˜ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ì œê³µí•œ **[ê¸°ì¤€ ë¦¬í¬ì§€í† ë¦¬ ë¶„ì„ ê²°ê³¼]**ì™€ **[ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­]**ì„ ê²°í•©í•˜ì—¬,
    **DBì—ì„œ ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ë¥¼ ì°¾ê¸° ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬**ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    ### ì…ë ¥ ë°ì´í„°
    1. **ê¸°ì¤€ ë¦¬í¬ì§€í† ë¦¬ ì •ë³´ (Context)**:
       {repo_context}
    
    2. **ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ (Instruction)**:
       - {user_request}

    ### ì‘ì—… ëª©í‘œ ë° ë°ì´í„° ì²˜ë¦¬ ì „ëµ
    1. **Contextê°€ ì¶©ë¶„í•  ê²½ìš° (ìƒì„¸ ìš”ì•½ ì¡´ì¬)**: ì œê³µëœ ê¸°ëŠ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ê¸°ìˆ ì  ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
    2. **Contextê°€ ë¶€ì¡±í•  ê²½ìš° (ì„¤ëª…/í† í”½ë§Œ ì¡´ì¬)**: í”„ë¡œì íŠ¸ ì´ë¦„ê³¼ í† í”½(Topic)ì„ ë³´ê³  ì´ í”„ë¡œì íŠ¸ê°€ ìˆ˜í–‰í•  ê¸°ëŠ¥ì„ **ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ (Infer)**í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.

    ### ê·œì¹™ (Strict)
    1. **Query (ê²€ìƒ‰ì–´)**:
       - ê¸°ì¤€ ë¦¬í¬ì§€í† ë¦¬ì˜ ì´ë¦„(ì˜ˆ: LangChain) ìì²´ë¥¼ ê²€ìƒ‰ì–´ë¡œ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤. (ê·¸ í”„ë¡œì íŠ¸ë¥¼ ì°¾ëŠ” ê²Œ ì•„ë‹ˆë¼ 'ë¹„ìŠ·í•œ ê²ƒ'ì„ ì°¾ëŠ” ê²ƒì´ë¯€ë¡œ)
       - ì¿¼ë¦¬ë¡œ ë¹„ìŠ·í•œ í”„ë¡œì íŠ¸ ì´ëŸ° ë‚´ìš©ë¥¼ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤. similar projects(X) ì´ëŸ° ê²½ìš°ëŠ” ì¿¼ë¦¬ë¥¼ ë¹„ì›Œë‘ì„¸ìš”
       - ëŒ€ì‹  **ê·¸ í”„ë¡œì íŠ¸ê°€ ë¬´ì—‡ì¸ì§€ ì •ì˜í•˜ëŠ” ê¸°ìˆ ì  ëª…ì‚¬êµ¬**ë¥¼ ë§Œë“œì‹­ì‹œì˜¤.
       - ì˜ˆì‹œ ìƒí™©:
         - Context: LangChain (LLM framework)
         - User: "ì´ê±°ë‘ ë¹„ìŠ·í•œë° Javaë¡œ ëœ ê±°"
         - **Result Query**: "LLM orchestration framework for Java applications" (LangChainì´ë¼ëŠ” ë‹¨ì–´ ëŒ€ì‹  ê¸°ëŠ¥ì„ ì„œìˆ )

    2. **Filters (í•„í„°)**:
       - **ë§¤ìš° ì¤‘ìš”**: ì‚¬ìš©ìê°€ "Javaë¡œ ëœ ê±°"ë¼ê³  í–ˆë‹¤ë©´ `filters: {{ "language": "Java" }}`ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€í•˜ì‹­ì‹œì˜¤.
       - ê¸°ì¤€ ë¦¬í¬ì§€í† ë¦¬ì˜ ì–¸ì–´ê°€ Pythonì´ì–´ë„, ì‚¬ìš©ìê°€ Javaë¥¼ ì›í•˜ë©´ Javaë¡œ í•„í„°ë§í•´ì•¼ í•©ë‹ˆë‹¤.
       - topic, license, languageê°€ ì§ì ‘ ì–¸ê¸‰ëœ ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´ ì§€ë‚˜ì¹˜ì„¸ìš”.

    ### ì¶œë ¥ í˜•ì‹ (JSON Only)
    {{
        "query": "string (ê¸°ìˆ ì  ì„œìˆ )",
        "keywords": ["í•µì‹¬ê¸°ìˆ 1", "í•µì‹¬ê¸°ìˆ 2"],
        "filters": {{ "language": "...", "topics": [...] }}
    }}
    """),
    ("user", "Analyze the context and instruction above, and generate the JSON query.")
])


async def generate_rag_query_and_filters(
    user_request: str,
    category: Literal["semantic_search", "url_analysis"],
    analyzed_data: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    [í•µì‹¬ ë¡œì§] 
    1. URL ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ -> 'ìœ ì‚¬ë„/ë§¥ë½ ê¸°ë°˜ ê²€ìƒ‰' ëª¨ë“œë¡œ ë™ì‘ (similarity_prompt)
    2. ì—†ìœ¼ë©´ -> 'ì¼ë°˜ ê²€ìƒ‰' ëª¨ë“œë¡œ ë™ì‘ (basic_search_prompt)
    """
    
    # --- 1. ëª¨ë“œ ê²°ì • ë° í”„ë¡¬í”„íŠ¸ ì„ íƒ ---
    if category == "url_analysis" and analyzed_data:
        print(f"âš™ï¸ [RAG Query Gen] Context-Aware Mode (URL Data Found)")
        
        # ë°ì´í„° ì¶”ì¶œ
        repo_snapshot = analyzed_data.get("repo_snapshot", {})
        readme_summary = analyzed_data.get("readme_summary", {})
        
        # [ìˆ˜ì •ë¨] Fallback Logicì„ ìœ„í•œ ë³€ìˆ˜ ì¤€ë¹„
        name = repo_snapshot.get('full_name', 'Unknown')
        description = repo_snapshot.get('description', '') or "" # None ë°©ì§€
        topics = repo_snapshot.get('topics', [])
        primary_lang = repo_snapshot.get('primary_language', 'Unknown')
        
        # ìš”ì•½ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ (ë„ˆë¬´ ì§§ê±°ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ë§Œ ìˆëŠ” ê²½ìš° ì œì™¸)
        raw_summary = readme_summary.get('final_summary', '')
        has_valid_summary = raw_summary and "No summary generated" not in raw_summary and len(raw_summary) > 50

        # === [Fallback Logic êµ¬í˜„] ===
        if has_valid_summary:
            # 1ìˆœìœ„: README ìš”ì•½ì´ ì¶©ì‹¤í•œ ê²½ìš° -> ê°€ì¥ ì •í™•í•¨
            source_info = "[Source: README Summary - High Reliability]"
            content_body = raw_summary
            
        elif description.strip():
            # 2ìˆœìœ„: ìš”ì•½ì€ ì—†ì§€ë§Œ Descriptionì€ ìˆëŠ” ê²½ìš° -> ì„¤ëª… ê¸°ë°˜
            source_info = "[Source: Repository Description - Medium Reliability]"
            content_body = description
            
        else:
            # 3ìˆœìœ„: ë‘˜ ë‹¤ ì—†ìŒ -> ì´ë¦„ê³¼ í† í”½ìœ¼ë¡œ ì¶”ë¡  í•„ìš”
            # í† í”½ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            topic_str = ", ".join(topics) if topics else "No topics provided"
            
            source_info = "[Source: Project Name & Topics - Inference Required]"
            content_body = f"""
            Project Name: {name}
            Topics/Tags: {topic_str}
            (No description available. Please infer functionality from the name and topics.)
            """

        # LLMì—ê²Œ ë˜ì ¸ì¤„ ìµœì¢… Context êµ¬ì„±
        repo_context_str = f"""
        {source_info}
        - Project Name: {name}
        - Main Language: {primary_lang}
        - Context Content:
        {content_body}
        """
        
        # ì²´ì¸ ì„¤ì •
        chain = similarity_search_prompt | llm
        input_vars = {
            "repo_context": repo_context_str,
            "user_request": user_request if user_request else "Find similar projects based on this architecture."
        }
        
    else:
        print(f"âš™ï¸ [RAG Query Gen] Basic Search Mode (No URL Data)")
        
        # ì²´ì¸ ì„¤ì •
        chain = basic_search_prompt | llm
        input_vars = {
            "user_request": user_request
        }

    # --- 2. LLM ì‹¤í–‰ ---
    try:
        response = await chain.ainvoke(input_vars)
        content = response.content
        
        # ğŸ’¡ [ë¡œê·¸]
        print(f"\n--- ğŸ¤– LLM Generated Query ({category}) ---")
        print(content)
        print("------------------------------------------\n")
        
        # JSON íŒŒì‹±
        content = content.strip()
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
            
        result_data = json.loads(content)
        
        return {
            "query": result_data.get("query", user_request),
            "keywords": result_data.get("keywords", []),
            "filters": result_data.get("filters", {})
        }
        
    except Exception as e:
        logger.error(f"[RAGQueryGen] Error: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {"query": user_request, "keywords": [], "filters": {}}