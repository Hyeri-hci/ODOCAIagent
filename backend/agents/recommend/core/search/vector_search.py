# core/search/vector_search.py
import json
import logging
import numpy as np
from typing import Dict, Any, List, Optional, Union
from qdrant_client import models
from flashrank import Ranker, RerankRequest
from datetime import timedelta, timezone # build_qdrant_filterì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìŒ

# ì–´ëŒ‘í„° ë° ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸ (ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
from adapters.qdrant_client import qdrant_client
from adapters.embedding_client import embedding_client
from core.qdrant.schemas import RepoSchema, ReadmeSchema

logger = logging.getLogger(__name__)

# =================================================================
# HELPER 1: JSON ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€ (float32 -> float ë³€í™˜)
# =================================================================
def convert_to_standard_types(data):
    """NumPy/Numpy ê¸°ë°˜ì˜ float32/64 ë“±ì„ í‘œì¤€ Python float/intë¡œ ë³€í™˜"""
    if isinstance(data, dict):
        return {k: convert_to_standard_types(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [convert_to_standard_types(item) for item in data]
        
    # ğŸŒŸ [í•µì‹¬ ìˆ˜ì •] np.float ëŒ€ì‹  í‘œì¤€ floatì„ ì‚¬ìš©í•˜ê±°ë‚˜, ëª…ì‹œì ì¸ np.float64ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # í‘œì¤€ floatê³¼ ëª…ì‹œì ì¸ NumPy íƒ€ì…ë§Œ ì²´í¬í•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.
    elif isinstance(data, (np.float32, np.float64, float)): 
        return float(data)
        
    elif isinstance(data, (np.integer, np.int64)):
        return int(data)
    else:
        return data

# -------------------------------------------------------------------
# HELPER 2: í•„í„° ë¹Œë” (Metadata + Keyword + ID)
# -------------------------------------------------------------------
def build_qdrant_filter(
    filters: Dict[str, Any] = None, 
    keywords: List[str] = None, 
    target_field: str = None,
    candidate_ids: List[int] = None
) -> Optional[models.Filter]:
    """
    Qdrant í•„í„° ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì´ì „ ì œê³µ ì½”ë“œì™€ ë™ì¼)
    """
    must_conditions = []
    
    # --- Helper Function for Range Logic ---
    def _create_range_condition(key: str, value: Any) -> Optional[models.FieldCondition]:
        range_obj = None
        if isinstance(value, (int, float)) or (isinstance(value, str) and value.isdigit()):
            range_obj = models.Range(gte=int(value))
        elif isinstance(value, list) and len(value) == 2:
            range_obj = models.Range(gte=value[0], lte=value[1])
        elif isinstance(value, dict):
            range_obj = models.Range(**value)
            
        if range_obj:
            return models.FieldCondition(key=key, range=range_obj)
        return None
    # ---------------------------------------

    # 1. ID í•„í„°ë§
    if candidate_ids:
        must_conditions.append(models.FieldCondition(
            key=RepoSchema.FIELD_PROJECT_ID, 
            match=models.MatchAny(any=candidate_ids)
        ))

    # 2. ë©”íƒ€ë°ì´í„° í•„í„° (Language, Stars, Forks ë“±)
    if filters:
        if filters.get("language"):
             # ... (ì–¸ì–´ í•„í„°ë§ ë¡œì§ ìƒëµ) ...
             lang_input = filters["language"]
             if isinstance(lang_input, list):
                 corrected_langs = []
                 for l in lang_input:
                     if isinstance(l, str):
                         if l.lower() == 'javascript': l = 'JavaScript'
                         elif l.lower() == 'typescript': l = 'TypeScript'
                         else: l = l.capitalize()
                         corrected_langs.append(l)
                 must_conditions.append(models.FieldCondition(
                     key=RepoSchema.FIELD_MAIN_LANG,
                     match=models.MatchAny(any=corrected_langs)
                 ))
             else:
                 lang = lang_input
                 if isinstance(lang, str):
                     if lang.lower() == 'javascript': lang = 'JavaScript'
                     elif lang.lower() == 'typescript': lang = 'TypeScript'
                     else: lang = lang.capitalize() 
                 must_conditions.append(models.FieldCondition(
                     key=RepoSchema.FIELD_MAIN_LANG,
                     match=models.MatchValue(value=lang) 
                 ))
        
        # License
        if filters.get("license"):
            must_conditions.append(models.FieldCondition(
                key=RepoSchema.FIELD_LICENSE,
                match=models.MatchValue(value=filters["license"])
            ))

        # Stars & Forks
        stars_val = filters.get("stars") or filters.get("min_stars")
        if stars_val:
            cond = _create_range_condition(RepoSchema.FIELD_STARS, stars_val)
            if cond: must_conditions.append(cond)
            
        forks_val = filters.get("forks") or filters.get("min_forks")
        if forks_val:
            cond = _create_range_condition(RepoSchema.FIELD_FORKS, forks_val)
            if cond: must_conditions.append(cond)

        # Topics
        if filters.get("topics"):
            must_conditions.append(models.FieldCondition(
                key=RepoSchema.FIELD_TOPICS,
                match=models.MatchAny(any=filters["topics"])
            ))

    # 3. í‚¤ì›Œë“œ í•„í„° (Step 2ì—ì„œ ë³¸ë¬¸ ê²€ìƒ‰ìš©)
    min_should_obj = None
    if keywords and target_field:
        kw_conditions = []
        for kw in keywords:
            kw_conditions.append(models.FieldCondition(
                key=target_field,
                match=models.MatchText(text=kw)
            ))
        
        if kw_conditions:
            min_should_obj = models.MinShould(
                conditions=kw_conditions,
                min_count=1 
            )

    if must_conditions or min_should_obj:
        return models.Filter(
            must=must_conditions if must_conditions else None,
            min_should=min_should_obj
        )
    return None

# -------------------------------------------------------------------
# VectorSearch Class
# -------------------------------------------------------------------
class VectorSearch:
    def __init__(self, broad_k: int = 100, fine_k: int = 5):
        self.embedding_client = embedding_client
        self.db_client = qdrant_client
        self.broad_k = broad_k
        self.fine_k = fine_k
        
        print("ğŸš€ [VectorSearch] Reranker ëª¨ë¸ ë¡œë”© ì¤‘...")
        # Ranker ê°ì²´ ì´ˆê¸°í™” (AttributeError í•´ê²°)
        self.ranker = Ranker(model_name="ms-marco-TinyBERT-L-2-v2", cache_dir="./model_cache")
        print("âœ… [VectorSearch] Reranker ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

    def search(self, query: str, filters: Optional[Dict[str, Any]] = None, keywords: List[str] = None) -> Dict[str, Any]:
        try:
            print(f"\n=========================================================================")
            print(f"ğŸ” [VectorSearch] Starting 3-Step Semantic Search for: '{query}'")
            print(f"=========================================================================")
            
            # ... (Step 1, 2, 3, 4 ê²€ìƒ‰ ë° ì¬ìˆœìœ„ ì§€ì • ë¡œì§ ìœ ì§€) ...
            
            # 1. ì¿¼ë¦¬ ë²¡í„°í™”
            query_vector = self.embedding_client.embed_query(query)
            
            
            # =========================================================
            # [Step 1] Broad Search (Desc DB)
            # =========================================================
            print(f"\n[Step 1] Broad Search (Desc DB, K={self.broad_k})...")
            
            broad_filter = build_qdrant_filter(
                filters=filters, 
                keywords=None, 
                target_field=RepoSchema.FIELD_DESC
            )
            
            print(f"   - Qdrant Filter applied: {'Yes' if broad_filter else 'No'}")

            candidates = self.db_client.search(
                embedding=query_vector, 
                collection_type='desc', 
                top_k=self.broad_k, 
                qdrant_filter=broad_filter,
                hnsw_ef=1024
            )
            
            print(f"   - Initial candidates found: {len(candidates)}.")
            
            # 1-2. [í™•ì¥ ê²€ìƒ‰] ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ í•„í„° ì™„í™”
            min_candidates_needed = self.broad_k // 2
            
            if len(candidates) < min_candidates_needed and filters:
                print(f"   âš ï¸ 1ì°¨ í›„ë³´ ë¶€ì¡± ({len(candidates)}ê°œ). í•„í„°ë¥¼ ì™„í™”í•˜ì—¬ í™•ì¥ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                
                relaxed_filters = filters.copy()
                relaxed_filters.pop("min_stars", None)
                relaxed_filters.pop("stars", None)
                relaxed_filters.pop("min_forks", None)
                relaxed_filters.pop("forks", None)
                
                if relaxed_filters != filters:
                    relaxed_filter_obj = build_qdrant_filter(
                        filters=relaxed_filters,
                        keywords=None,
                        target_field=RepoSchema.FIELD_DESC
                    )
                    
                    fill_count = self.broad_k - len(candidates)
                    extra_candidates = self.db_client.search(
                        embedding=query_vector, 
                        collection_type='desc', 
                        top_k=fill_count, 
                        qdrant_filter=relaxed_filter_obj,
                        hnsw_ef=512
                    )
                    
                    existing_ids = {c['id'] for c in candidates}
                    for extra in extra_candidates:
                        if extra['id'] not in existing_ids:
                            candidates.append(extra)
                            existing_ids.add(extra['id'])
                            
                    print(f"   âœ… í™•ì¥ ê²€ìƒ‰ í›„ ì´ í›„ë³´: {len(candidates)}ê°œ")

            if not candidates:
                print("âŒ [Step 1 Fail] ìµœì¢… í›„ë³´ í™•ë³´ ì‹¤íŒ¨.")
                return {
                    "search_query": query, 
                    "message": "ì¡°ê±´ì— ë§ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì „í˜€ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    "final_recommendations": []
                }

            candidate_ids = [item['id'] for item in candidates]
            print(f"   - IDs passed to Step 2: {len(candidate_ids)}.")

            # =========================================================
            # [Step 2] Fine Search (Readme DB)
            # =========================================================
            print(f"\n[Step 2] Fine Search (Readme DB, Target K={self.fine_k * 3})...")
            
            fine_filter = build_qdrant_filter(
                filters=None, 
                keywords=keywords, 
                target_field=ReadmeSchema.FIELD_CONTENT,
                candidate_ids=candidate_ids 
            )
            
            print(f"   - Readme Filter applied: {'Yes' if fine_filter else 'No'}. Keywords used: {keywords is not None}")

            raw_results = self.db_client.search(
                embedding=query_vector, 
                collection_type='readme', 
                top_k=self.fine_k * 3, 
                qdrant_filter=fine_filter,
                hnsw_ef=512
            )
            print(f"   - Step 2 Readme results found: {len(raw_results)}.")

            # [Fallback] Readme í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ IDë¡œë§Œ ì¬ê²€ìƒ‰
            if (not raw_results or len(raw_results) < self.fine_k) and keywords:
                print(f"   âš ï¸ Readme ë§¤ì¹­ ë¶€ì¡±. í‚¤ì›Œë“œ í•„í„° ì—†ì´ ë³´ì¶© ê²€ìƒ‰ ìˆ˜í–‰.")
                
                found_ids = {r['id'] for r in raw_results}
                remaining_ids = [cid for cid in candidate_ids if cid not in found_ids]
                
                if remaining_ids:
                    fallback_filter = build_qdrant_filter(
                        filters=None, 
                        keywords=None, 
                        candidate_ids=remaining_ids
                    )
                    needed = (self.fine_k * 2) - len(raw_results)
                    fallback_results = self.db_client.search(
                        embedding=query_vector, 
                        collection_type='readme', 
                        top_k=max(needed, 5),
                        qdrant_filter=fallback_filter,
                        hnsw_ef=512
                    )
                    raw_results.extend(fallback_results)
                    print(f"   âœ… ë³´ì¶© ê²€ìƒ‰ í›„ Readme ì´ ê²°ê³¼: {len(raw_results)}ê°œ.")


            if not raw_results:
                print("   âš ï¸ Readme ë°ì´í„° ì—†ìŒ. Description ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                final_fallback = []
                for cand in candidates[:self.fine_k]:
                     cand_filled = cand.copy()
                     desc_text = cand.get('desc', 'ì„¤ëª… ì—†ìŒ')
                     cand_filled['content'] = f"[Description] {desc_text}"
                     final_fallback.append(cand_filled)
                        
                return {
                     "search_query": query,
                     "final_recommendations": final_fallback
                }

            # =========================================================
            # [Step 3] Grouping & Reranking
            # =========================================================
            print(f"\n[Step 3] Grouping & Reranking (Fine K={self.fine_k})...")
            
            seen_project_ids = set()
            unique_results = []
            
            for res in raw_results:
                pid = res.get('id')
                if pid not in seen_project_ids:
                    seen_project_ids.add(pid)
                    unique_results.append({
                        "id": pid,
                        "text": res.get('content', ''), 
                        "meta": res 
                    })
            
            print(f"   - Unique projects for Reranking: {len(unique_results)}.")

            final_recommendations = []
            if unique_results:
                # 3-1. Reranking ìˆ˜í–‰
                rerank_request = RerankRequest(query=query, passages=unique_results)
                ranked_results = self.ranker.rerank(rerank_request)
                
                final_top_k = ranked_results[:self.fine_k]
                
                for item in final_top_k:
                    original_data = item['meta']
                    original_data['rerank_score'] = item['score'] 
                    
                    # [Source Marking] Readmeì—ì„œ ì°¾ì€ ê²½ìš° ì¶œì²˜ í‘œì‹œ
                    raw_content = original_data.get('content', '')
                    original_data['content'] = f"[Readme] {raw_content}"
                    
                    final_recommendations.append(original_data)
            else:
                print("   âš ï¸ Rerankí•  ìœ íš¨ ë°ì´í„° ì—†ìŒ. Description ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                for cand in candidates[:self.fine_k]:
                     cand_filled = cand.copy()
                     desc_text = cand.get('desc', 'ì„¤ëª… ì—†ìŒ')
                     cand_filled['content'] = f"[Description] {desc_text}"
                     final_recommendations.append(cand_filled)

            # =========================================================
            # [Step 4] Final Padding (ìµœì¢… ë³´ì¶©)
            # =========================================================
            if len(final_recommendations) < self.fine_k:
                print(f"   âš ï¸ ìµœì¢… ê²°ê³¼ ë¶€ì¡± ({len(final_recommendations)}/{self.fine_k}). Desc í›„ë³´êµ°ì—ì„œ ë³´ì¶©í•©ë‹ˆë‹¤.")
                existing_final_ids = {item.get('id') for item in final_recommendations}
                
                for cand in candidates:
                    if len(final_recommendations) >= self.fine_k:
                        break
                    
                    if cand['id'] not in existing_final_ids:
                        cand_filled = cand.copy()
                        desc_text = cand.get('desc', 'ì„¤ëª… ì—†ìŒ')
                        cand_filled['content'] = f"[Description] {desc_text}"
                        
                        final_recommendations.append(cand_filled)

            print(f"âœ… [VectorSearch Complete] Total final recommendations: {len(final_recommendations)}.")

            return {
                "search_query": query,
                "final_recommendations": final_recommendations
            }

        except Exception as e:
            logger.error(f"âŒ [VectorSearch] Critical Error: {e}")
            return {"error": str(e), "final_recommendations": []}

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
vector_search_engine = VectorSearch()