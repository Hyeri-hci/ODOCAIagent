import logging
from typing import Dict, Any, List, Optional
from qdrant_client import models
from flashrank import Ranker, RerankRequest

from backend.agents.recommend.adapters.qdrant_client import qdrant_client
from backend.agents.recommend.adapters.embedding_client import get_embedding_client
from backend.agents.recommend.core.qdrant.schemas import RepoSchema, ReadmeSchema

logger = logging.getLogger(__name__)

# =================================================================
# FILTER BUILDER
# =================================================================
def build_qdrant_filter(filters: Dict[str, Any]) -> Optional[models.Filter]:
    """LLMì´ ì¶”ì¶œí•œ filters ë”•ì…”ë„ˆë¦¬ë¥¼ Qdrant Filter ê°ì²´ë¡œ ë³€í™˜"""
    must_conditions = []
    
    if filters:
        # 1. Language (Exact Match)
        if filters.get("language"):
            must_conditions.append(models.FieldCondition(
                key=RepoSchema.FIELD_MAIN_LANG, 
                match=models.MatchValue(value=filters["language"])
            ))

        # 2. Topics (í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ OK - MatchAny)
        if filters.get("topics"):
            must_conditions.append(models.FieldCondition(
                key=RepoSchema.FIELD_TOPICS, 
                match=models.MatchAny(any=filters["topics"])
            ))

        # 3. Stars (Range: gte)
        # LLMì´ ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ìì—´("1000")ë¡œ ì¤„ ê²½ìš° ëŒ€ë¹„í•´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        star_val = filters.get("min_stars") or filters.get("stars")
        if star_val:
            try:
                must_conditions.append(models.FieldCondition(
                    key=RepoSchema.FIELD_STARS, 
                    range=models.Range(gte=int(star_val))
                ))
            except ValueError:
                logger.warning(f"Invalid star count in filter: {star_val}")

    return models.Filter(must=must_conditions) if must_conditions else None


# =================================================================
# MAIN SEARCH ENGINE (Ensemble + Rerank)
# =================================================================
class VectorSearch:
    def __init__(self):
        self.db_client = qdrant_client
        self.embedding_client = get_embedding_client()  # lazy initialization
        
        # Reranker ëª¨ë¸ ë¡œë”© (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ ë°œìƒ)
        # model_nameì„ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ default(ms-marco-TinyBERT-L-2-v2) ì‚¬ìš©
        self.ranker = Ranker(model_name="ms-marco-TinyBERT-L-2-v2", cache_dir="./model_cache")

    def search(
        self, 
        query: str, 
        filters: Dict[str, Any] = {},
        target_k: int = 10 
    ) -> Dict[str, Any]:
        """
        [Ensemble Search Pipeline]
        1. Description ê²€ìƒ‰ (Route A)
        2. Readme ê²€ìƒ‰ (Route B)
        3. ê²°ê³¼ ë³‘í•© (Merge & Deduplication)
        4. Reranking -> Final Top-K
        """
        logger.info(f"ğŸ” [VectorSearch] Ensemble Search: '{query}' | Filters: {filters}")
        
        # 0. ì¿¼ë¦¬ ì„ë² ë”©
        query_vector = self.embedding_client.embed_query(query)
        if not query_vector:
            logger.error("Query embedding failed.")
            return {"error": "Embedding failed", "final_recommendations": []}

        # í›„ë³´êµ° í¬ê¸° ì„¤ì • (Reranking íš¨ê³¼ë¥¼ ìœ„í•´ 3~4ë°°ìˆ˜ í™•ë³´)
        candidate_k = target_k * 10

        # ---------------------------------------------------------
        # [Route A & B] ë³‘ë ¬ ê²€ìƒ‰
        # ---------------------------------------------------------
        common_filter = build_qdrant_filter(filters=filters)
        
        # 1. Description ê²€ìƒ‰ (ë¦¬ë“œë¯¸ ì—†ëŠ” í”„ë¡œì íŠ¸ë„ ì—¬ê¸°ì„œ ì¡í˜)
        desc_hits = self.db_client.search(
            embedding=query_vector,
            collection_type='desc',
            top_k=candidate_k,
            qdrant_filter=common_filter
        )
        logger.info(f" 1ï¸âƒ£ Description Hits: {len(desc_hits)}")

        # 2. Readme ê²€ìƒ‰ (ìƒì„¸ ë‚´ìš© ê¸°ë°˜ ê²€ìƒ‰)
        # ì£¼ì˜: Readme Collectionì—ë„ Filter í•„ë“œ(language ë“±)ê°€ ìˆì–´ì•¼ ê²°ê³¼ê°€ ë‚˜ì˜´
        readme_hits = self.db_client.search(
            embedding=query_vector,
            collection_type='readme',
            top_k=candidate_k,
            qdrant_filter=common_filter
        )
        logger.info(f" 2ï¸âƒ£ Readme Hits: {len(readme_hits)}")

        # ---------------------------------------------------------
        # [Merge] ê²°ê³¼ ë³‘í•© (ì „ëµ: Descriptionì„ ë² ì´ìŠ¤ë¡œ í•˜ë˜, Readme ë§¤ì¹­ ì‹œ ë®ì–´ì“°ê¸°)
        # ---------------------------------------------------------
        merged_candidates = {} 

        # A. Desc ê²°ê³¼ ì²˜ë¦¬
        for hit in desc_hits:
            pid = hit['id']
            merged_candidates[pid] = {
                "id": pid,
                "content": f"[Project Description] {hit['content']}", 
                "meta": hit['meta'],
                "base_score": hit['score'],
                "source": "description"
            }

        # B. Readme ê²°ê³¼ ë³‘í•©
        for hit in readme_hits:
            pid = hit['id']
            
            # ë©”íƒ€ë°ì´í„° Joinì— ì‹¤íŒ¨í•œ Readme ê²°ê³¼ëŠ” ì‹ ë¢°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œì™¸
            if not hit.get('meta'): 
                continue

            content_snippet = f"[Readme Snippet] {hit['content']}"

            if pid in merged_candidates:
                # ì´ë¯¸ Descriptionìœ¼ë¡œ ì°¾ì•˜ì§€ë§Œ, Readme ë‚´ìš©ì´ ë” êµ¬ì²´ì ì´ë¯€ë¡œ ì—…ë°ì´íŠ¸
                # (ì„ íƒì‚¬í•­: ë‘˜ ë‹¤ í•©ì³ì„œ Rerankingì— ë³´ë‚¼ ìˆ˜ë„ ìˆìŒ)
                merged_candidates[pid]['content'] = content_snippet
                merged_candidates[pid]['source'] = "readme_and_desc"
                # ì ìˆ˜ëŠ” ë³´í†µ Readme ë§¤ì¹­ ì ìˆ˜ê°€ ë” ì˜ë¯¸ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—…ë°ì´íŠ¸
                merged_candidates[pid]['base_score'] = max(merged_candidates[pid]['base_score'], hit['score'])
            else:
                # Description ê²€ìƒ‰ì—” ì•ˆ ê±¸ë ¸ì§€ë§Œ Readme ë‚´ìš©ìœ¼ë¡œ ì°¾ì€ ê²½ìš° (Hidden Gem)
                merged_candidates[pid] = {
                    "id": pid,
                    "content": content_snippet,
                    "meta": hit['meta'],
                    "base_score": hit['score'],
                    "source": "readme_only"
                }

        candidates_list = list(merged_candidates.values())
        logger.info(f" 3ï¸âƒ£ Merged Unique Candidates: {len(candidates_list)}")
        
        if not candidates_list:
            return {
                "search_query": query, 
                "final_recommendations": [], 
                "message": "No matching projects found."
            }

        # ---------------------------------------------------------
        # [Rerank] ìµœì¢… ìˆœìœ„ ê²°ì •
        # ---------------------------------------------------------
        # FlashRank í¬ë§·ì— ë§ì¶° ë°ì´í„° ë³€í™˜
        passages = [
            {"id": str(c['id']), "text": c['content'], "meta": c['meta']}
            for c in candidates_list
        ]

        try:
            rerank_request = RerankRequest(query=query, passages=passages)
            ranked_results = self.ranker.rerank(rerank_request)
        except Exception as e:
            logger.error(f"Reranking failed: {e}. Returning vector search results.")
            # Rerank ì‹¤íŒ¨ ì‹œ ë²¡í„° ì ìˆ˜ìˆœ ì •ë ¬ë¡œ ëŒ€ì²´
            ranked_results = sorted(passages, key=lambda x: x.get('score', 0), reverse=True)

        # ğŸ¯ Final Top-K Cut
        final_top_k = ranked_results[:target_k]
        
        final_output = []
        for item in final_top_k:
            meta = item['meta']
            # Rerank ì ìˆ˜ì™€ ë§¤ì¹­ëœ ìŠ¤ë‹ˆí«ì„ ë©”íƒ€ì— ì¶”ê°€ (UI í‘œì‹œìš©)
            meta['rerank_score'] = item['score'] 
            # item['text']ì—ëŠ” "[Readme Snippet] ..." íƒœê·¸ê°€ ë¶™ì–´ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            meta['match_snippet'] = item['text'][:300] + "..." 
            final_output.append(meta)

        logger.info(f" âœ… Final Recommendations: {len(final_output)}")

        return {
            "search_query": query,
            "final_recommendations": final_output
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (lazy initialization)
_vector_search_engine = None

def get_vector_search_engine():
    """VectorSearch ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (lazy initialization)"""
    global _vector_search_engine
    if _vector_search_engine is None:
        _vector_search_engine = VectorSearch()
    return _vector_search_engine

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í”„ë¡œí¼í‹° (ì§ì ‘ ì ‘ê·¼ ì‹œì—ë„ lazy init)
class _VectorSearchProxy:
    def __getattr__(self, name):
        return getattr(get_vector_search_engine(), name)

vector_search_engine = _VectorSearchProxy()