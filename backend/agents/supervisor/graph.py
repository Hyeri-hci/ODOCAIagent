"""
Supervisor Graph - ì„¸ì…˜ ê¸°ë°˜ ë©”íƒ€ ì—ì´ì „íŠ¸
"""

from typing import Dict, Any, Optional, Literal
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
import logging

from backend.agents.supervisor.models import SupervisorState
from backend.agents.supervisor.intent_parser import SupervisorIntentParserV2
from backend.agents.diagnosis.graph import run_diagnosis
from backend.common.session import get_session_store, Session
from backend.common.metrics import get_trace_manager
from backend.common.pronoun_resolver import resolve_pronoun, detect_implicit_context

logger = logging.getLogger(__name__)


# === í—¬í¼ í•¨ìˆ˜ ===

async def _enhance_answer_with_context(
    user_message: str,
    base_answer: str,
    referenced_data: Dict[str, Any],
    action: str,
    refers_to: str = "previous data"
) -> str:
    """ëŒ€ëª…ì‚¬ ì°¸ì¡° ì‹œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ë³´ê°•"""
    try:
        from backend.llm.factory import fetch_llm_client
        from backend.llm.base import ChatRequest, ChatMessage, Role
        import asyncio
        import json
        
        llm = fetch_llm_client()
        loop = asyncio.get_event_loop()
        
        # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
        context_summary = json.dumps(referenced_data, ensure_ascii=False, indent=2)[:1000]
        
        action_instructions = {
            "refine": "ë” ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ",
            "summarize": "ê°„ë‹¨í•˜ê³  í•µì‹¬ì ìœ¼ë¡œ",
            "view": "ëª…í™•í•˜ê²Œ"
        }
        
        instruction = action_instructions.get(action, "ëª…í™•í•˜ê²Œ")
        
        prompt = f"""ì‚¬ìš©ìê°€ ì´ì „ ëŒ€í™”ì—ì„œ ìƒì„±ëœ '{refers_to}' ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ì—¬ ì§ˆë¬¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.

=== ì‚¬ìš©ì ì§ˆë¬¸ ===
{user_message}

=== ì°¸ì¡° ë°ì´í„° ('{refers_to}') ===
{context_summary}

=== ì§€ì‹œì‚¬í•­ ===
ì‚¬ìš©ìì˜ ìš”ì²­ì„ {instruction} ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì°¸ì¡° ë°ì´í„°ì˜ ì£¼ìš” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ì€ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ì°¸ì¡° ë°ì´í„°ì˜ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""
        
        request = ChatRequest(
            messages=[ChatMessage(role="user", content=prompt)],
            temperature=0.7,
            max_tokens=1000
        )
        
        response = await loop.run_in_executor(None, llm.chat, request)
        enhanced_answer = response.content
        
        logger.info(f"Enhanced answer with context from '{refers_to}'")
        return enhanced_answer
    
    except Exception as e:
        logger.error(f"Failed to enhance answer: {e}", exc_info=True)
        return base_answer


# === ë…¸ë“œ í•¨ìˆ˜ë“¤ ===

async def load_or_create_session_node(state: SupervisorState) -> Dict[str, Any]:
    """ì„¸ì…˜ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
    session_store = get_session_store()
    
    session_id = state.get("session_id")
    
    if session_id:
        # ê¸°ì¡´ ì„¸ì…˜ ë¡œë“œ
        session = session_store.get_session(session_id)
        if session:
            logger.info(f"Session loaded: {session_id}")
            return {
                "is_new_session": False,
                "conversation_history": session.conversation_history,
                "accumulated_context": dict(session.accumulated_context)
            }
        else:
            logger.warning(f"Session not found or expired: {session_id}")
    
    # ìƒˆ ì„¸ì…˜ ìƒì„±
    session = session_store.create_session(
        owner=state["owner"],
        repo=state["repo"],
        ref=state.get("ref", "main")
    )
    
    logger.info(f"New session created: {session.session_id}")
    
    return {
        "session_id": session.session_id,
        "is_new_session": True,
        "conversation_history": [],
        "accumulated_context": {}
    }


async def parse_intent_node(state: SupervisorState) -> Dict[str, Any]:
    """
    ì˜ë„ íŒŒì‹± (Supervisor Intent Parser V2)
    
    íë¦„:
    1. ëŒ€ëª…ì‚¬ í•´ê²° (ë§¥ë½ ì¶”ë¡ )
    2. ì €ì¥ì†Œ ê°ì§€ (owner/repo íŒ¨í„´ + GitHub ê²€ìƒ‰)
    3. Clarification ì‘ë‹µ ì²˜ë¦¬ (ìˆ«ì ì„ íƒ ë“±)
    4. ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    5. LLM ì˜ë„ íŒŒì‹± (IntentParserV2)
    """
    import re
    from backend.common.github_client import search_repositories
    from backend.common.intent_utils import extract_experience_level
    
    logger.info("Parsing supervisor intent")
    
    user_message = state.get("user_message") or ""
    user_context = state.get("user_context", {}) or {}
    conversation_history = state.get("conversation_history", [])
    accumulated_context = dict(state.get("accumulated_context", {}))
    
    # === user_messageê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì§„ë‹¨ìœ¼ë¡œ ë¼ìš°íŒ… ===
    if not user_message.strip():
        logger.info("No user message provided, defaulting to diagnosis")
        return {
            "supervisor_intent": {
                "task_type": "diagnosis",
                "target_agent": "diagnosis",
                "needs_clarification": False,
                "confidence": 1.0,
                "reasoning": "No user message, defaulting to diagnosis"
            },
            "needs_clarification": False,
            "clarification_questions": [],
            "target_agent": "diagnosis",
            "detected_intent": "diagnose_repo",
            "intent_confidence": 1.0,
            "decision_reason": "No user message provided"
        }
    
    # === 0ë‹¨ê³„: force_diagnosis ì²´í¬ ===
    # /api/analyze/streamì—ì„œë„ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì—ì´ì „íŠ¸ ë¼ìš°íŒ…
    if user_context.get("force_diagnosis"):
        msg_lower_check = user_message.lower()
        
        # ë³´ì•ˆ í‚¤ì›Œë“œ ì²´í¬
        security_keywords = ["ë³´ì•ˆ", "ì·¨ì•½ì ", "security", "cve", "vulnerability", "ì˜ì¡´ì„± ì·¨ì•½"]
        if any(kw in msg_lower_check for kw in security_keywords):
            logger.info("force_diagnosis: routing to security agent based on keywords")
            return {
                "supervisor_intent": {
                    "task_type": "security",
                    "target_agent": "security",
                    "needs_clarification": False,
                    "confidence": 0.95,
                    "reasoning": "ë³´ì•ˆ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"
                },
                "needs_clarification": False,
                "clarification_questions": [],
                "target_agent": "security",
                "detected_intent": "security_scan",
                "intent_confidence": 0.95,
                "decision_reason": "security keywords detected"
            }
        
        # ì˜¨ë³´ë”© í‚¤ì›Œë“œ ì²´í¬
        onboarding_keywords = ["ì˜¨ë³´ë”©", "ê¸°ì—¬", "contribute", "ê°€ì´ë“œ", "ì°¸ì—¬", "ì‹œì‘í•˜ê³  ì‹¶"]
        if any(kw in msg_lower_check for kw in onboarding_keywords):
            logger.info("force_diagnosis: routing to onboarding agent based on keywords")
            return {
                "supervisor_intent": {
                    "task_type": "onboarding",
                    "target_agent": "onboarding",
                    "needs_clarification": False,
                    "confidence": 0.95,
                    "reasoning": "ì˜¨ë³´ë”© ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€"
                },
                "needs_clarification": False,
                "clarification_questions": [],
                "target_agent": "onboarding",
                "detected_intent": "build_onboarding_plan",
                "intent_confidence": 0.95,
                "decision_reason": "onboarding keywords detected"
            }
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ + ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ LLM ì˜ë„ íŒŒì‹±
        if user_message.strip():
            logger.info("force_diagnosis: no keyword match, using LLM intent parsing")
            try:
                session_context = {
                    "owner": state.get("owner", ""),
                    "repo": state.get("repo", ""),
                    "accumulated_context": {},
                    "pronoun_detected": False
                }
                
                parser = SupervisorIntentParserV2()
                intent = await parser.parse(
                    user_message=user_message,
                    session_context=session_context
                )
                
                return {
                    "supervisor_intent": intent.dict(),
                    "needs_clarification": intent.needs_clarification,
                    "clarification_questions": intent.clarification_questions,
                    "target_agent": intent.target_agent,
                    "detected_intent": intent.task_type,
                    "intent_confidence": intent.confidence,
                    "decision_reason": f"LLM parsed: {intent.reasoning}"
                }
            except Exception as e:
                logger.warning(f"LLM intent parsing failed: {e}, defaulting to diagnosis")
        
        # ê¸°ë³¸ê°’: ì§„ë‹¨ (ë©”ì‹œì§€ ì—†ê±°ë‚˜ LLM ì‹¤íŒ¨)
        logger.info("force_diagnosis: defaulting to diagnosis agent")
        return {
            "supervisor_intent": {
                "task_type": "diagnosis",
                "target_agent": "diagnosis",
                "needs_clarification": False,
                "confidence": 1.0,
                "reasoning": "force_diagnosis flag set (default)"
            },
            "needs_clarification": False,
            "clarification_questions": [],
            "target_agent": "diagnosis",
            "detected_intent": "diagnose_repo",
            "intent_confidence": 1.0,
            "decision_reason": "force_diagnosis flag enabled (default)"
        }
    
    msg_lower = user_message.lower()
    
    # === 1ë‹¨ê³„: ëŒ€ëª…ì‚¬ í•´ê²° (ë§¥ë½ ì¶”ë¡ ) ===
    resolved_message = user_message
    pronoun_detected = False
    
    try:
        from backend.common.pronoun_resolver import resolve_pronoun
        from backend.common.session import ConversationTurn, AccumulatedContext
        from typing import List, cast
        
        if conversation_history and isinstance(conversation_history, list):
            typed_history: List[ConversationTurn] = []
            for turn in conversation_history:
                if isinstance(turn, dict):
                    typed_history.append(cast(ConversationTurn, turn))
            
            typed_context = cast(AccumulatedContext, accumulated_context)
            
            pronoun_result = resolve_pronoun(
                user_message=user_message,
                conversation_history=typed_history,
                accumulated_context=typed_context
            )
            
            if pronoun_result.get("resolved"):
                pronoun_detected = True
                logger.info(f"Pronoun resolved: {pronoun_result.get('pattern')} -> {pronoun_result.get('refers_to')}")
                accumulated_context["last_pronoun_reference"] = pronoun_result
    except Exception as e:
        logger.warning(f"Pronoun resolution failed: {e}")
    
    # === 2ë‹¨ê³„: ì €ì¥ì†Œ ê°ì§€ ===
    detected_owner = None
    detected_repo = None
    search_results = None
    
    # 2-1. owner/repo íŒ¨í„´ (ì˜ˆ: facebook/react)
    repo_pattern = r'([a-zA-Z0-9_-]+)/([a-zA-Z0-9_.-]+)'
    repo_match = re.search(repo_pattern, user_message)
    if repo_match:
        detected_owner = repo_match.group(1)
        detected_repo = repo_match.group(2)
        logger.info(f"Detected repo from message: {detected_owner}/{detected_repo}")
        accumulated_context["last_mentioned_repo"] = {
            "owner": detected_owner,
            "repo": detected_repo,
            "full_name": f"{detected_owner}/{detected_repo}"
        }
    
    # 2-2. ë‹¨ë… í”„ë¡œì íŠ¸ëª… (ì˜ˆ: "react ë¶„ì„í•´ì¤˜")
    if not detected_repo:
        exclude_keywords = [
            "ë¶„ì„", "ì§„ë‹¨", "í•´ì¤˜", "í•´ì£¼ì„¸ìš”", "ì°¾ì•„", "ì•Œë ¤", 
            "ë³´ì—¬", "ì „ì²´", "ê±´ê°•ë„", "ì˜¨ë³´ë”©", "ë³´ì•ˆ", "ì·¨ì•½ì ",
            "ì´", "ì €ì¥ì†Œ", "í”„ë¡œì íŠ¸", "ë¼ëŠ”", "ë¥¼", "ì„", "ì¢€",
            "ë­ì•¼", "ë­”ê°€", "ì–´ë•Œ", "ì–´ë–»ê²Œ", "ì–´ë–¤"
        ]
        
        words = user_message.split()
        potential_project = None
        
        for word in words:
            word_clean = word.strip().rstrip("?!ëŠ”ë€ì´ê°€ì„ë¥¼").lower()
            if len(word_clean) >= 2 and word_clean[0].isalpha():
                if word_clean not in exclude_keywords:
                    potential_project = word_clean
                    break
        
        if potential_project and len(potential_project) >= 2:
            logger.info(f"Searching for project: {potential_project}")
            try:
                search_results = search_repositories(potential_project, max_results=5)
                
                if search_results:
                    # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­ ìš°ì„ 
                    exact_match = None
                    for r in search_results:
                        if r["repo"].lower() == potential_project:
                            exact_match = r
                            break
                    
                    if exact_match:
                        detected_owner = exact_match["owner"]
                        detected_repo = exact_match["repo"]
                        logger.info(f"Exact match found: {detected_owner}/{detected_repo}")
                    elif search_results[0]["stars"] >= 10000:
                        top = search_results[0]
                        if potential_project in top["repo"].lower():
                            detected_owner = top["owner"]
                            detected_repo = top["repo"]
                            logger.info(f"Top popular match: {detected_owner}/{detected_repo}")
                    
                    if detected_owner and detected_repo:
                        accumulated_context["last_mentioned_repo"] = {
                            "owner": detected_owner,
                            "repo": detected_repo,
                            "full_name": f"{detected_owner}/{detected_repo}"
                        }
            except Exception as e:
                logger.warning(f"GitHub search failed: {e}")
    
    # 2-3. last_mentioned_repoì—ì„œ ë³µì›
    if not detected_repo:
        last_mentioned = accumulated_context.get("last_mentioned_repo", {})
        if last_mentioned.get("owner") and last_mentioned.get("repo"):
            detected_owner = last_mentioned["owner"]
            detected_repo = last_mentioned["repo"]
            logger.info(f"Using last mentioned repo: {detected_owner}/{detected_repo}")
    
    # === 3ë‹¨ê³„: Clarification ì‘ë‹µ ì²˜ë¦¬ (ìˆ«ì ì„ íƒ) ===
    # ì´ì „ í„´ì—ì„œ clarification ìš”ì²­í–ˆìœ¼ë©´ ì‘ë‹µ ì²˜ë¦¬
    if conversation_history:
        last_turn = conversation_history[-1] if conversation_history else None
        if last_turn:
            last_response = last_turn.get("agent_response", "")
            last_intent = last_turn.get("resolved_intent", {})
            
            # ì €ì¥ì†Œ ì„ íƒ ì‘ë‹µ (pending_search_results)
            pending_results = accumulated_context.get("pending_search_results", [])
            if pending_results and ("ì–´ë–¤ ì €ì¥ì†Œë¥¼" in last_response):
                try:
                    selection = int(user_message.strip()) - 1
                    if 0 <= selection < len(pending_results):
                        selected = pending_results[selection]
                        logger.info(f"User selected repo: {selected['full_name']}")
                        
                        new_context = dict(accumulated_context)
                        new_context.pop("pending_search_results", None)
                        new_context["last_mentioned_repo"] = {
                            "owner": selected["owner"],
                            "repo": selected["repo"],
                            "full_name": selected["full_name"]
                        }
                        
                        return {
                            "supervisor_intent": {
                                "task_type": "diagnosis",
                                "target_agent": "diagnosis",
                                "needs_clarification": False,
                                "confidence": 0.95,
                                "reasoning": f"ì‚¬ìš©ìê°€ {selected['full_name']} ì„ íƒ"
                            },
                            "needs_clarification": False,
                            "clarification_questions": [],
                            "target_agent": "diagnosis",
                            "owner": selected["owner"],
                            "repo": selected["repo"],
                            "accumulated_context": new_context
                        }
                except (ValueError, IndexError):
                    pass
            
            # ê²½í—˜ ìˆ˜ì¤€ ì‘ë‹µ
            if "ê²½í—˜ ìˆ˜ì¤€ì„ ì•Œë ¤ì£¼ì„¸ìš”" in last_response or last_intent.get("needs_clarification"):
                experience_level = extract_experience_level(user_message)
                
                # ìˆ«ì ì‘ë‹µ ì²˜ë¦¬
                if not experience_level:
                    msg_stripped = user_message.strip()
                    if msg_stripped == "1":
                        experience_level = "beginner"
                    elif msg_stripped == "2":
                        experience_level = "intermediate"
                    elif msg_stripped == "3":
                        experience_level = "advanced"
                
                if experience_level:
                    logger.info(f"Experience level from clarification: {experience_level}")
                    new_context = dict(accumulated_context)
                    user_profile = new_context.get("user_profile", {})
                    user_profile["experience_level"] = experience_level
                    new_context["user_profile"] = user_profile
                    
                    return {
                        "supervisor_intent": {
                            "task_type": "onboarding",
                            "target_agent": "onboarding",
                            "needs_clarification": False,
                            "confidence": 0.95,
                            "reasoning": f"Clarification ì‘ë‹µì—ì„œ ê²½í—˜ ìˆ˜ì¤€ '{experience_level}' ê°ì§€"
                        },
                        "needs_clarification": False,
                        "clarification_questions": [],
                        "target_agent": "onboarding",
                        "accumulated_context": new_context
                    }
    
    # === 4ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ëŸ¬ ê°œë©´ clarification ìš”ì²­ ===
    if search_results and len(search_results) > 1 and not detected_owner:
        options = []
        for i, r in enumerate(search_results[:3], 1):
            stars_str = f"{r['stars']:,}" if r['stars'] >= 1000 else str(r['stars'])
            options.append(f"{i}. {r['full_name']} (ìŠ¤íƒ€: {stars_str})")
        
        question = f"ë‹¤ìŒ ì¤‘ ì–´ë–¤ ì €ì¥ì†Œë¥¼ ë¶„ì„í• ê¹Œìš”?\n" + "\n".join(options)
        
        new_context = dict(accumulated_context)
        new_context["pending_search_results"] = search_results[:3]
        
        return {
            "supervisor_intent": {
                "task_type": "clarification",
                "target_agent": None,
                "needs_clarification": True,
                "confidence": 0.7,
                "reasoning": "ì—¬ëŸ¬ ì €ì¥ì†Œ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì„ íƒ í•„ìš”"
            },
            "needs_clarification": True,
            "clarification_questions": [question],
            "target_agent": None,
            "accumulated_context": new_context
        }
    
    # === 5ë‹¨ê³„: ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ===
    session_context = {
        "owner": state["owner"],
        "repo": state["repo"],
        "ref": state.get("ref", "main"),
        "conversation_history": conversation_history,
        "accumulated_context": accumulated_context,
        "pronoun_detected": pronoun_detected,
        "detected_repo": f"{detected_owner}/{detected_repo}" if detected_owner else None
    }
    
    # === 6ë‹¨ê³„: LLM ì˜ë„ íŒŒì‹± ===
    parser = SupervisorIntentParserV2()
    intent = await parser.parse(
        user_message=resolved_message,
        session_context=session_context
    )
    
    needs_clarification = intent.needs_clarification
    clarification_questions = intent.clarification_questions
    
    if needs_clarification:
        logger.info(f"Clarification needed: {clarification_questions}")
    
    result = {
        "supervisor_intent": intent.dict(),
        "needs_clarification": needs_clarification,
        "clarification_questions": clarification_questions,
        "target_agent": intent.target_agent,
        "additional_agents": intent.additional_agents,  # ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…
        "accumulated_context": accumulated_context
    }
    
    # LLMì´ detected_repoë¥¼ ë°˜í™˜í–ˆìœ¼ë©´ ì„¸ì…˜ ì—…ë°ì´íŠ¸
    if intent.detected_repo:
        try:
            parts = intent.detected_repo.split("/")
            if len(parts) == 2:
                result["owner"] = parts[0]
                result["repo"] = parts[1]
                logger.info(f"LLM detected repo: {intent.detected_repo}")
                
                accumulated_context["last_mentioned_repo"] = {
                    "owner": parts[0],
                    "repo": parts[1],
                    "full_name": intent.detected_repo
                }
                result["accumulated_context"] = accumulated_context
        except Exception as e:
            logger.warning(f"Failed to parse detected_repo: {e}")
    
    # ê·œì¹™ ê¸°ë°˜ detected_owner/detected_repo ìš°ì„ 
    if detected_owner and detected_repo:
        result["owner"] = detected_owner
        result["repo"] = detected_repo
        logger.info(f"Using pre-detected repo: {detected_owner}/{detected_repo}")
    
    return result


def check_clarification_node(state: SupervisorState) -> Literal["clarification_response", "route_to_agent"]:
    """Clarification í•„ìš” ì—¬ë¶€ ì²´í¬"""
    if state.get("needs_clarification", False):
        return "clarification_response"
    return "route_to_agent"


async def clarification_response_node(state: SupervisorState) -> Dict[str, Any]:
    """ëª…í™•í™” ì§ˆë¬¸ ì‘ë‹µ"""
    questions = state.get("clarification_questions", [])
    
    response = "ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n"
    for i, q in enumerate(questions, 1):
        response += f"{i}. {q}\n"
    
    return {
        "final_answer": response,
        "awaiting_clarification": True
    }


async def run_diagnosis_agent_node(state: SupervisorState) -> Dict[str, Any]:
    """ì§„ë‹¨ Agent ì‹¤í–‰"""
    logger.info("Running Diagnosis Agent V2")
    
    result = await run_diagnosis(
        owner=state["owner"],
        repo=state["repo"],
        ref=state.get("ref", "main"),
        user_message=state["user_message"],
        supervisor_intent=state.get("supervisor_intent")
    )
    
    return {
        "agent_result": result,
        "iteration": state.get("iteration", 0) + 1
    }


async def run_onboarding_agent_node(state: SupervisorState) -> Dict[str, Any]:
    """ì˜¨ë³´ë”© Agent ì‹¤í–‰ - run_onboarding_graph ì‚¬ìš©"""
    logger.info("Running Onboarding Agent via graph")
    
    from backend.agents.onboarding.graph import run_onboarding_graph
    
    # ì§„ë‹¨ ê²°ê³¼ê°€ í•„ìš”
    accumulated_context = state.get("accumulated_context", {})
    diagnosis_result = accumulated_context.get("diagnosis_result")
    
    if not diagnosis_result:
        logger.warning("Diagnosis result not found, running diagnosis first")
        # Diagnosis ë¨¼ì € ì‹¤í–‰
        diagnosis_result = await run_diagnosis(
            owner=state["owner"],
            repo=state["repo"],
            ref=state.get("ref", "main")
        )
    
    # ì‚¬ìš©ì ë ˆë²¨ ê²°ì • (ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ë‚˜ ì˜ë„ì—ì„œ ì¶”ì¶œ)
    session_profile = accumulated_context.get("user_profile", {})
    user_level = session_profile.get("experience_level", "beginner")
    
    # ì˜¨ë³´ë”© ê·¸ë˜í”„ ì‹¤í–‰
    try:
        onboarding_result = await run_onboarding_graph(
            owner=state["owner"],
            repo=state["repo"],
            experience_level=user_level,
            diagnosis_summary=diagnosis_result,
            user_context=accumulated_context.get("user_context", {}),
            user_message=state.get("user_message"),
            ref=state.get("ref", "main")
        )
        
        plan = onboarding_result.get("plan", [])
        summary = onboarding_result.get("summary", "")
        
        result = {
            "type": "onboarding_plan",
            "plan": plan,
            "summary": summary or f"{len(plan)}ì£¼ì°¨ ì˜¨ë³´ë”© ê°€ì´ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "agent_analysis": onboarding_result.get("agent_analysis", {})
        }
        
        logger.info(f"Onboarding plan created via graph: {len(plan)} weeks")
        
    except Exception as e:
        logger.error(f"Onboarding graph execution failed: {e}", exc_info=True)
        result = {
            "type": "onboarding_plan",
            "error": str(e),
            "message": "ì˜¨ë³´ë”© í”Œëœ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    
    return {
        "agent_result": result,
        "iteration": state.get("iteration", 0) + 1
    }


async def run_security_agent_node(state: SupervisorState) -> Dict[str, Any]:
    """ë³´ì•ˆ Agent ì‹¤í–‰ (SecurityAgent ì—°ê²°)"""
    import os
    logger.info("Running Security Agent")
    
    try:
        from backend.agents.security.agent.security_agent import SecurityAgent
        
        # SecurityAgent ì´ˆê¸°í™”
        agent = SecurityAgent(
            llm_base_url=os.getenv("LLM_BASE_URL", ""),
            llm_api_key=os.getenv("LLM_API_KEY", ""),
            llm_model=os.getenv("LLM_MODEL", "gpt-4"),
            llm_temperature=float(os.getenv("LLM_TEMPERATURE", "0.1")),
            execution_mode="fast"  # supervisorì—ì„œëŠ” ë¹ ë¥¸ ëª¨ë“œ ì‚¬ìš©
        )
        
        # ë¶„ì„ ìš”ì²­ êµ¬ì„±
        user_message = state.get("user_message", "")
        owner = state.get("owner", "")
        repo = state.get("repo", "")
        
        # SecurityAgent ì‹¤í–‰
        result = await agent.analyze(
            user_request=user_message if user_message else f"{owner}/{repo} ë³´ì•ˆ ë¶„ì„",
            owner=owner,
            repository=repo,
            github_token=os.getenv("GITHUB_TOKEN")
        )
        
        logger.info(f"Security analysis completed: success={result.get('success', False)}")
        
        # type í•„ë“œ ì¶”ê°€ (finalize_answer_nodeì—ì„œ ì‚¬ìš©)
        result["type"] = "security_scan"
        
        return {
            "agent_result": result,
            "security_result": result,  # finalizeì—ì„œ ì‚¬ìš©
            "iteration": state.get("iteration", 0) + 1
        }
        
    except ImportError as e:
        logger.warning(f"SecurityAgent import failed: {e}")
        return {
            "agent_result": {
                "type": "security_scan",
                "message": f"ë³´ì•ˆ ì—ì´ì „íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}",
                "status": "import_error"
            },
            "iteration": state.get("iteration", 0) + 1
        }
    except Exception as e:
        logger.error(f"Security analysis failed: {e}")
        return {
            "agent_result": {
                "type": "security_scan",
                "message": f"ë³´ì•ˆ ë¶„ì„ ì˜¤ë¥˜: {e}",
                "status": "error"
            },
            "iteration": state.get("iteration", 0) + 1
        }


async def run_contributor_agent_node(state: SupervisorState) -> Dict[str, Any]:
    """ì‹ ê·œ ê¸°ì—¬ì ì§€ì› ì—ì´ì „íŠ¸ ì‹¤í–‰ (ì²« ê¸°ì—¬ ê°€ì´ë“œ, ì´ìŠˆ ë§¤ì¹­, ì²´í¬ë¦¬ìŠ¤íŠ¸ ë“±)"""
    logger.info("Running Contributor Agent")
    
    try:
        from backend.common.contribution_guide import (
            generate_first_contribution_guide,
            format_guide_as_markdown,
            generate_contribution_checklist,
            format_checklist_as_markdown
        )
        from backend.common.issue_matcher import (
            match_issues_to_user,
            format_matched_issues_as_markdown
        )
        from backend.common.structure_visualizer import (
            generate_structure_visualization,
            format_structure_as_markdown
        )
        from backend.common.community_analyzer import (
            analyze_community_activity,
            format_community_analysis_as_markdown
        )
        
        owner = state.get("owner", "")
        repo = state.get("repo", "")
        user_message = state.get("user_message", "").lower()
        
        result = {
            "type": "contributor",
            "owner": owner,
            "repo": repo,
            "features": {}
        }
        
        # ì²« ê¸°ì—¬ ê°€ì´ë“œ (ê¸°ë³¸ ì œê³µ)
        guide = generate_first_contribution_guide(owner, repo)
        result["features"]["first_contribution_guide"] = guide
        
        # ê¸°ì—¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ ì œê³µ)
        checklist = generate_contribution_checklist(owner, repo)
        result["features"]["contribution_checklist"] = checklist
        
        # ìš”ì²­ì— ë”°ë¼ ì¶”ê°€ ê¸°ëŠ¥ í™œì„±í™”
        if any(kw in user_message for kw in ["êµ¬ì¡°", "í´ë”", "structure"]):
            # ì½”ë“œ êµ¬ì¡° ì‹œê°í™” (íŒŒì¼ íŠ¸ë¦¬ í•„ìš” - accumulated_contextì—ì„œ ê°€ì ¸ì˜´)
            accumulated_context = state.get("accumulated_context", {})
            file_tree = accumulated_context.get("file_tree", [])
            if file_tree:
                visualization = generate_structure_visualization(owner, repo, file_tree)
                result["features"]["structure_visualization"] = visualization
        
        if any(kw in user_message for kw in ["ì´ìŠˆ", "issue", "good first"]):
            # Good First Issue ë§¤ì¹­ (accumulated_contextì—ì„œ ì´ìŠˆ ì •ë³´ ê°€ì ¸ì˜´)
            accumulated_context = state.get("accumulated_context", {})
            issues = accumulated_context.get("open_issues", [])
            if issues:
                matched = match_issues_to_user(issues, experience_level="beginner")
                result["features"]["issue_matching"] = matched
        
        if any(kw in user_message for kw in ["ì»¤ë®¤ë‹ˆí‹°", "í™œë™", "community"]):
            # ì»¤ë®¤ë‹ˆí‹° í™œë™ ë¶„ì„
            accumulated_context = state.get("accumulated_context", {})
            prs = accumulated_context.get("recent_prs", [])
            issues = accumulated_context.get("recent_issues", [])
            contributors = accumulated_context.get("contributors", [])
            
            community = analyze_community_activity(
                owner, repo, 
                recent_prs=prs, 
                recent_issues=issues, 
                contributors=contributors
            )
            result["features"]["community_analysis"] = community
        
        # ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ìƒì„±
        summary_md = f"# {owner}/{repo} ê¸°ì—¬ ê°€ì´ë“œ\n\n"
        summary_md += format_guide_as_markdown(guide)
        summary_md += "\n---\n"
        summary_md += format_checklist_as_markdown(checklist)
        result["summary_markdown"] = summary_md
        
        logger.info(f"Contributor agent completed: {list(result['features'].keys())}")
        
        return {
            "agent_result": result,
            "iteration": state.get("iteration", 0) + 1
        }
        
    except ImportError as e:
        logger.warning(f"Contributor agent import failed: {e}")
        return {
            "agent_result": {
                "type": "contributor",
                "message": f"ê¸°ì—¬ì ì§€ì› ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}",
                "status": "import_error"
            },
            "iteration": state.get("iteration", 0) + 1
        }
    except Exception as e:
        logger.error(f"Contributor agent failed: {e}")
        return {
            "agent_result": {
                "type": "contributor",
                "message": f"ê¸°ì—¬ì ì§€ì› ì‹¤í–‰ ì˜¤ë¥˜: {e}",
                "status": "error"
            },
            "iteration": state.get("iteration", 0) + 1
        }


async def run_recommend_agent_node(state: SupervisorState) -> Dict[str, Any]:
    """ì¶”ì²œ ì—ì´ì „íŠ¸ ì‹¤í–‰ (onboarding ì ìˆ˜ ê¸°ë°˜ í”„ë¡œì íŠ¸ ì¶”ì²œ)"""
    logger.info("Running Recommend Agent")
    
    try:
        from backend.agents.recommend.agent.graph import run_recommend
        
        owner = state.get("owner", "")
        repo = state.get("repo", "")
        user_message = state.get("user_message", "")
        
        # ì¶”ì²œ ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await run_recommend(
            owner=owner,
            repo=repo,
            user_message=user_message
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        search_results = result.get("search_results", [])
        final_summary = result.get("final_summary", "")
        
        formatted_result = {
            "type": "recommend",
            "recommendations": [],
            "summary": final_summary
        }
        
        # onboarding ì ìˆ˜ ê¸°ì¤€ í•„í„°ë§ (70ì  ì´ìƒ)
        for item in search_results:
            # RecommendSnapshot ê°ì²´ì¸ ê²½ìš° ì†ì„± ì ‘ê·¼
            if hasattr(item, "onboarding_score"):
                onboarding_score = item.onboarding_score or 0
                if onboarding_score >= 70:
                    formatted_result["recommendations"].append({
                        "name": getattr(item, "name", ""),
                        "full_name": getattr(item, "full_name", ""),
                        "description": getattr(item, "description", ""),
                        "stars": getattr(item, "stars", 0),
                        "onboarding_score": onboarding_score,
                        "ai_reason": getattr(item, "ai_reason", "")
                    })
            elif isinstance(item, dict):
                onboarding_score = item.get("onboarding_score", 0) or 0
                if onboarding_score >= 70:
                    formatted_result["recommendations"].append(item)
        
        logger.info(f"Recommend agent completed: {len(formatted_result['recommendations'])} projects")
        
        return {
            "agent_result": formatted_result,
            "iteration": state.get("iteration", 0) + 1
        }
        
    except ImportError as e:
        logger.warning(f"Recommend agent import failed: {e}")
        return {
            "agent_result": {
                "type": "recommend",
                "message": f"ì¶”ì²œ ì—ì´ì „íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}",
                "status": "import_error"
            },
            "iteration": state.get("iteration", 0) + 1
        }
    except Exception as e:
        logger.error(f"Recommend agent failed: {e}")
        return {
            "agent_result": {
                "type": "recommend",
                "message": f"ì¶”ì²œ ì‹¤í–‰ ì˜¤ë¥˜: {e}",
                "status": "error"
            },
            "iteration": state.get("iteration", 0) + 1
        }


async def chat_response_node(state: SupervisorState) -> Dict[str, Any]:
    """ì¼ë°˜ ì±„íŒ… ì‘ë‹µ"""
    logger.info("Generating chat response")
    
    user_message = state.get("user_message") or ""
    
    # user_messageê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
    if not user_message.strip():
        answer = "ì•ˆë…•í•˜ì„¸ìš”! ì €ì¥ì†Œ ë¶„ì„ì´ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
        return {
            "agent_result": {"type": "chat", "response": answer},
            "final_answer": answer
        }
    
    try:
        from backend.llm.factory import fetch_llm_client
        from backend.llm.base import ChatRequest, ChatMessage
        import asyncio
        
        llm = fetch_llm_client()
        loop = asyncio.get_event_loop()
        
        request = ChatRequest(
            messages=[
                ChatMessage(role="user", content=user_message)
            ]
        )
        
        response = await loop.run_in_executor(None, llm.chat, request)
        answer = response.content
    except Exception as e:
        logger.warning(f"LLM call failed, using fallback: {e}")
        # Fallback ì‘ë‹µ
        answer = f"ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤: {user_message}\n\nì €ì¥ì†Œ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° ownerì™€ repoë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”."
    
    return {
        "agent_result": {"type": "chat", "response": answer},
        "final_answer": answer
    }


async def finalize_answer_node(state: SupervisorState) -> Dict[str, Any]:
    """ìµœì¢… ë‹µë³€ ìƒì„± (ëŒ€ëª…ì‚¬ í•´ê²° ì»¨í…ìŠ¤íŠ¸ í¬í•¨)"""
    logger.info("Finalizing answer")
    
    agent_result = state.get("agent_result")
    
    if not agent_result:
        return {"final_answer": "ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "error": "No agent result"}
    
    # ëŒ€ëª…ì‚¬ í•´ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    accumulated_context = state.get("accumulated_context", {})
    pronoun_info = accumulated_context.get("last_pronoun_reference", {})
    user_message = state["user_message"]
    
    # ëŒ€ëª…ì‚¬ ì°¸ì¡°ê°€ ìˆëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    referenced_data = None
    if pronoun_info.get("resolved") and pronoun_info.get("confidence", 0) > 0.5:
        refers_to = pronoun_info.get("refers_to")
        if refers_to and refers_to in accumulated_context:
            referenced_data = accumulated_context.get(refers_to)
            logger.info(f"Using referenced data from: {refers_to}")
    
    # ê²°ê³¼ íƒ€ì…ì— ë”°ë¼ ë‹µë³€ í¬ë§·íŒ…
    result_type = agent_result.get("type", "unknown")
    
    if result_type == "full_diagnosis":
        # ì§„ë‹¨ ê²°ê³¼ ìš”ì•½
        owner = agent_result.get("owner", state.get("owner", ""))
        repo = agent_result.get("repo", state.get("repo", ""))
        health_score = agent_result.get("health_score", 0)
        onboarding_score = agent_result.get("onboarding_score", 0)
        health_level = agent_result.get("health_level", "")
        docs_score = agent_result.get("docs_score", 0)
        activity_score = agent_result.get("activity_score", 0)
        
        # ìš”ì•½ (llm_summaryê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ êµ¬ì„±)
        summary = agent_result.get("llm_summary", "")
        if not summary:
            # llm_summaryê°€ ì—†ìœ¼ë©´ ì§ì ‘ êµ¬ì„±
            warnings = agent_result.get("warnings", [])
            recommendations = agent_result.get("recommendations", [])
            
            summary_parts = []
            if health_score >= 80:
                summary_parts.append(f"ì „ë°˜ì ìœ¼ë¡œ ê±´ê°•í•œ ì €ì¥ì†Œì…ë‹ˆë‹¤.")
            elif health_score >= 60:
                summary_parts.append(f"ë³´í†µ ìˆ˜ì¤€ì˜ ê±´ê°•ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.")
            else:
                summary_parts.append(f"ê°œì„ ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤.")
            
            if warnings:
                summary_parts.append(f"ì£¼ì˜ì‚¬í•­: {', '.join(warnings[:2])}")
            
            summary = " ".join(summary_parts)
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        key_findings = agent_result.get("key_findings", [])
        findings_text = ""
        if key_findings:
            for finding in key_findings[:3]:
                title = finding.get('title', '')
                desc = finding.get('description', '')
                if title and desc:
                    findings_text += f"- **{title}**: {desc}\n"
                elif title:
                    findings_text += f"- {title}\n"
        else:
            # key_findingsê°€ ì—†ìœ¼ë©´ recommendations ì‚¬ìš©
            recommendations = agent_result.get("recommendations", [])
            if recommendations:
                for rec in recommendations[:3]:
                    findings_text += f"- {rec}\n"
        
        answer = f"""## {owner}/{repo} ì§„ë‹¨ ê²°ê³¼

**ê±´ê°•ë„:** {health_score}/100
**ì˜¨ë³´ë”© ì ìˆ˜:** {onboarding_score}/100
**ë¬¸ì„œí™” ì ìˆ˜:** {docs_score}/100
**í™œë™ì„± ì ìˆ˜:** {activity_score}/100

{summary}

**ì£¼ìš” ë°œê²¬ì‚¬í•­:**
{findings_text if findings_text else "- íŠ¹ì´ì‚¬í•­ ì—†ìŒ"}
"""
        
        # í”„ë¡œì•¡í‹°ë¸Œ ì œì•ˆ (ì ìˆ˜ ê¸°ë°˜ ì¡°ê±´ë¶€ ìƒì„±)
        suggested_actions = []
        
        # ê±´ê°•ë„ê°€ ë‚®ìœ¼ë©´ ë³´ì•ˆ ì ê²€ ì¶”ì²œ
        if health_score < 50:
            suggested_actions.append({
                "action": "ë³´ì•ˆ ì·¨ì•½ì  ì ê²€ ì¶”ì²œ",
                "type": "security",
                "reason": f"ê±´ê°•ë„ê°€ {health_score}ì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤. ë³´ì•ˆ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            })
        
        # ì˜¨ë³´ë”© ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ê¸°ì—¬ ê°€ì´ë“œ ì¶”ì²œ
        if onboarding_score >= 70:
            suggested_actions.append({
                "action": "ê¸°ì—¬ ê°€ì´ë“œ ìƒì„± ê°€ëŠ¥",
                "type": "onboarding",
                "reason": f"ì˜¨ë³´ë”© ì ìˆ˜ê°€ {onboarding_score}ì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤. ê¸°ì—¬ ê°€ì´ë“œë¥¼ ë§Œë“¤ì–´ ë³´ì„¸ìš”."
            })
        
        # ê¸°ë³¸ ì œì•ˆ ì¶”ê°€
        suggested_actions.extend([
            {"action": "ì˜¨ë³´ë”© ê°€ì´ë“œ ë§Œë“¤ê¸°", "type": "onboarding"},
            {"action": "ë³´ì•ˆ ìŠ¤ìº” ì‹¤í–‰", "type": "security"}
        ])
        
        # AI íŒë‹¨ ê·¼ê±° (Agentic ìš”ì†Œ ê°€ì‹œí™”)
        decision_reason = state.get("decision_reason", "")
        supervisor_intent = state.get("supervisor_intent", {})
        reasoning = supervisor_intent.get("reasoning", "") if isinstance(supervisor_intent, dict) else ""
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ (ì§„ë‹¨â†’ì˜¨ë³´ë”© ì—°ê²°)
        next_steps = """
---
**ë‹¤ìŒ ë‹¨ê³„:**
ì´ ì €ì¥ì†Œì— ê¸°ì—¬í•˜ê³  ì‹¶ë‹¤ë©´ `ì˜¨ë³´ë”© ê°€ì´ë“œ ë§Œë“¤ì–´ì¤˜`ë¼ê³  ë§í•´ë³´ì„¸ìš”!
ë³´ì•ˆ ì·¨ì•½ì ì´ ê±±ì •ëœë‹¤ë©´ `ë³´ì•ˆ ë¶„ì„í•´ì¤˜`ë¼ê³  ìš”ì²­í•˜ì„¸ìš”.
"""
        
        # AI íŒë‹¨ ê·¼ê±° ì„¹ì…˜ (reasoningì´ ìˆìœ¼ë©´ í‘œì‹œ)
        ai_trace = ""
        if reasoning or decision_reason:
            ai_trace = f"""
---
**[AI íŒë‹¨ ê³¼ì •]**
{reasoning or decision_reason}
"""
        
        answer = answer + ai_trace + next_steps
        
        return {
            "final_answer": answer,
            "suggested_actions": suggested_actions,
            "decision_trace": {
                "reasoning": reasoning,
                "decision_reason": decision_reason,
                "target_agent": state.get("target_agent"),
                "intent_confidence": state.get("intent_confidence", 0)
            }
        }
    
    elif result_type == "quick_query":
        # ë¹ ë¥¸ ì¡°íšŒ ê²°ê³¼
        target = agent_result.get("target", "")
        data = agent_result.get("data", {})
        
        answer = f"## {target.upper()} ì •ë³´\n\n"
        
        if target == "readme":
            content = data.get("content", "")
            answer += content[:500] + "..." if len(content) > 500 else content
        else:
            answer += str(data)
        
        return {"final_answer": answer}
    
    elif result_type == "reinterpret":
        # ì¬í•´ì„ ê²°ê³¼
        return {"final_answer": agent_result.get("reinterpreted_answer", "")}
    
    elif result_type == "onboarding_plan":
        # ì˜¨ë³´ë”© í”Œëœ ê²°ê³¼
        plan = agent_result.get("plan", {})
        summary = agent_result.get("summary", "")
        
        if plan:
            # planì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì£¼ì°¨ë³„ í”Œëœ)
            if isinstance(plan, list):
                steps_preview = "\n".join([
                    f"{i+1}. {step.get('title', step.get('week', f'Week {i+1}'))}" 
                    for i, step in enumerate(plan[:5]) if isinstance(step, dict)
                ])
                more_steps = "\n... (ë” ë³´ê¸°)" if len(plan) > 5 else ""
                prereqs = ""
                difficulty = "normal"
            else:
                # planì´ dictì¸ ê²½ìš°
                steps_preview = "\n".join([
                    f"{i+1}. {step.get('title', '')}" 
                    for i, step in enumerate(plan.get('steps', [])[:5]) if isinstance(step, dict)
                ])
                more_steps = "\n... (ë” ë³´ê¸°)" if len(plan.get('steps', [])) > 5 else ""
                prereqs = ', '.join(plan.get('prerequisites', [])[:3])
                difficulty = plan.get('difficulty', 'normal')
            
            answer = f"""**ì˜¨ë³´ë”© í”Œëœ ìƒì„± ì™„ë£Œ**

{summary}

**ì£¼ìš” ë‹¨ê³„:**
{steps_preview if steps_preview else "- ìƒì„¸ ë‹¨ê³„ëŠ” í”Œëœì„ ì°¸ì¡°í•˜ì„¸ìš”"}{more_steps}

**ë‚œì´ë„:** {difficulty}
{"**í•„ìš” ì‚¬ì „ì§€ì‹:** " + prereqs if prereqs else ""}
"""
        else:
            answer = f"**ì˜¨ë³´ë”© í”Œëœ**\n\n{agent_result.get('message', 'ì˜¨ë³´ë”© í”Œëœì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.')}"
        
        return {"final_answer": answer}
    
    elif result_type == "security_scan":
        # ë³´ì•ˆ ë¶„ì„ ê²°ê³¼
        results = agent_result.get("results", {})
        security_score = results.get("security_score", agent_result.get("security_score"))
        security_grade = results.get("security_grade", agent_result.get("security_grade", "N/A"))
        risk_level = results.get("risk_level", agent_result.get("risk_level", "unknown"))
        vulnerabilities = results.get("vulnerabilities", {})
        vuln_total = vulnerabilities.get("total", 0)
        vuln_critical = vulnerabilities.get("critical", 0)
        vuln_high = vulnerabilities.get("high", 0)
        vuln_medium = vulnerabilities.get("medium", 0)
        vuln_low = vulnerabilities.get("low", 0)
        
        # ì·¨ì•½ì  ìš”ì•½
        if vuln_total == 0:
            vuln_summary = "ë°œê²¬ëœ ì·¨ì•½ì ì´ ì—†ìŠµë‹ˆë‹¤."
        else:
            parts = []
            if vuln_critical > 0:
                parts.append(f"ğŸ”´ Critical: {vuln_critical}")
            if vuln_high > 0:
                parts.append(f"ğŸŸ  High: {vuln_high}")
            if vuln_medium > 0:
                parts.append(f"ğŸŸ¡ Medium: {vuln_medium}")
            if vuln_low > 0:
                parts.append(f"ğŸŸ¢ Low: {vuln_low}")
            vuln_summary = " | ".join(parts) if parts else f"ì´ {vuln_total}ê°œì˜ ì·¨ì•½ì "
        
        owner = state.get("owner", "")
        repo = state.get("repo", "")
        
        answer = f"""## {owner}/{repo} ë³´ì•ˆ ë¶„ì„ ê²°ê³¼

**ë³´ì•ˆ ì ìˆ˜:** {security_score}/100 (ë“±ê¸‰: {security_grade})
**ìœ„í—˜ë„:** {risk_level}

### ì·¨ì•½ì  í˜„í™©
{vuln_summary}

ë³´ì•ˆ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸ ì •ë³´ëŠ” ìš°ì¸¡ ë³´ê³ ì„œì˜ "ë³´ì•ˆ ë¶„ì„" ì„¹ì…˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.
"""
        
        return {"final_answer": answer}
    
    elif result_type == "contributor":
        # ê¸°ì—¬ì ê°€ì´ë“œ ê²°ê³¼
        features = agent_result.get("features", {})
        owner = state.get("owner", "")
        repo = state.get("repo", "")
        
        guide = features.get("first_contribution_guide", {})
        checklist = features.get("contribution_checklist", {})
        
        # ì²« ê¸°ì—¬ ê°€ì´ë“œ ìš”ì•½
        guide_summary = ""
        steps = guide.get("steps", [])
        if steps:
            guide_summary = "\n".join([
                f"{i+1}. {step.get('title', '')}"
                for i, step in enumerate(steps[:5])
            ])
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½
        checklist_items = checklist.get("items", [])
        checklist_summary = ""
        if checklist_items:
            high_priority = [item for item in checklist_items if item.get("priority") == "high"]
            checklist_summary = "\n".join([f"  - {item.get('title', '')}" for item in high_priority[:3]])
        
        answer = f"""## {owner}/{repo} ê¸°ì—¬ì ê°€ì´ë“œ

**ì²« ê¸°ì—¬ë¥¼ ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!**

### ì£¼ìš” ë‹¨ê³„
{guide_summary if guide_summary else "ìƒì„¸ ê°€ì´ë“œë¥¼ ìš°ì¸¡ ë¦¬í¬íŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”."}

### PR ì œì¶œ ì „ í•„ìˆ˜ ì²´í¬
{checklist_summary if checklist_summary else "ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìš°ì¸¡ ë¦¬í¬íŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”."}

---
**íŒ:** ìš°ì¸¡ì˜ \"ê¸°ì—¬ì ê°€ì´ë“œ\" ì„¹ì…˜ì—ì„œ ìƒì„¸ ì •ë³´ì™€ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Good First Issueë¥¼ ì°¾ìœ¼ì‹œë ¤ë©´ `ì´ìŠˆ ì¶”ì²œí•´ì¤˜`ë¼ê³  ë§í•´ë³´ì„¸ìš”!
"""
        
        return {"final_answer": answer}
    
    else:
        # ê¸°íƒ€ - ëŒ€ëª…ì‚¬ ì°¸ì¡° ì²˜ë¦¬
        answer = str(agent_result.get("message", agent_result.get("response", str(agent_result))))
        
        # ëŒ€ëª…ì‚¬ ì°¸ì¡°ê°€ ìˆê³  referenced_dataê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if referenced_data and pronoun_info.get("action") in ["refine", "summarize", "view"]:
            try:
                # LLMìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì‘ë‹µ ìƒì„±
                answer = await _enhance_answer_with_context(
                    user_message=user_message,
                    base_answer=answer,
                    referenced_data=referenced_data,
                    action=pronoun_info.get("action"),
                    refers_to=pronoun_info.get("refers_to")
                )
            except Exception as e:
                logger.warning(f"Failed to enhance answer with context: {e}")
        
        return {"final_answer": answer}


async def update_session_node(state: SupervisorState) -> Dict[str, Any]:
    """ì„¸ì…˜ ì—…ë°ì´íŠ¸"""
    session_id = state.get("session_id")
    if not session_id:
        return {}
    
    session_store = get_session_store()
    session = session_store.get_session(session_id)
    
    if not session:
        logger.warning(f"Session not found for update: {session_id}")
        return {}
    
    # í„´ ì¶”ê°€
    data_generated = []
    agent_result = state.get("agent_result")
    target_agent = state.get("target_agent")
    
    result_updates = {}  # ìµœì¢… stateì— ë°˜í™˜í•  ê°’ë“¤
    
    if agent_result and isinstance(agent_result, dict):
        result_type = agent_result.get("type")
        
        # Diagnosis ê²°ê³¼ ì €ì¥
        if result_type == "full_diagnosis" or target_agent == "diagnosis":
            data_generated.append("diagnosis_result")
            session.update_context("diagnosis_result", agent_result)
            session.update_context("last_topic", "diagnosis")
            result_updates["diagnosis_result"] = agent_result  # stateì—ë„ ë°˜í™˜
            logger.info("Stored diagnosis_result in session context")
        
        # Onboarding ê²°ê³¼ ì €ì¥
        elif result_type == "onboarding_plan" or target_agent == "onboarding":
            data_generated.append("onboarding_plan")
            session.update_context("onboarding_plan", agent_result)
            session.update_context("last_topic", "onboarding")
            result_updates["onboarding_result"] = agent_result
            logger.info("Stored onboarding_plan in session context")
        
        # Security ê²°ê³¼ ì €ì¥
        elif result_type == "security_scan" or target_agent == "security":
            data_generated.append("security_scan")
            session.update_context("security_scan", agent_result)
            session.update_context("last_topic", "security")
            result_updates["security_result"] = agent_result
            logger.info("Stored security_scan in session context")
        
        # Contributor ê²°ê³¼ ì €ì¥
        elif result_type == "contributor" or target_agent == "contributor":
            data_generated.append("contributor_guide")
            session.update_context("contributor_guide", agent_result)
            session.update_context("last_topic", "contributor")
            result_updates["contributor_result"] = agent_result
            logger.info("Stored contributor_guide in session context")
        
        # Chat ê²°ê³¼ë„ ì €ì¥ (ì°¸ì¡° ê°€ëŠ¥í•˜ë„ë¡)
        elif result_type == "chat" or target_agent == "chat":
            session.update_context("last_chat_response", agent_result)
            session.update_context("last_topic", "chat")
            logger.info("Stored chat response in session context")
    
    session.add_turn(
        user_message=state["user_message"],
        resolved_intent=state.get("supervisor_intent") or {},
        execution_path=state.get("target_agent") or "unknown",
        agent_response=state.get("final_answer") or "",
        data_generated=data_generated,
        execution_time_ms=0  # TraceManager ì—°ë™ ì‹œ ì¸¡ì • ê°€ëŠ¥
    )
    
    session_store.update_session(session)
    logger.info(f"Session updated: {session_id}")
    
    return result_updates


# === ë¼ìš°íŒ… í•¨ìˆ˜ ===

def route_to_agent_node(state: SupervisorState) -> Literal[
    "run_diagnosis_agent", "run_onboarding_agent", "run_security_agent", "chat_response"
]:
    """Target agentë¡œ ë¼ìš°íŒ…"""
    target = state.get("target_agent")
    
    if not target:
        return "chat_response"
    
    if target == "diagnosis":
        return "run_diagnosis_agent"
    elif target == "onboarding":
        return "run_onboarding_agent"
    elif target == "security":
        return "run_security_agent"
    else:
        return "chat_response"


async def run_additional_agents_node(state: SupervisorState) -> Dict[str, Any]:
    """ì¶”ê°€ ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰ (ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…)"""
    additional_agents = state.get("additional_agents", [])
    
    if not additional_agents:
        return {}
    
    logger.info(f"Running additional agents: {additional_agents}")
    
    multi_agent_results = dict(state.get("multi_agent_results", {}))
    
    # ë©”ì¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ì €ì¥
    main_result = state.get("agent_result")
    target_agent = state.get("target_agent")
    if main_result and target_agent:
        multi_agent_results[target_agent] = main_result
    
    for agent_name in additional_agents:
        logger.info(f"Running additional agent: {agent_name}")
        
        try:
            if agent_name == "diagnosis":
                result = await run_diagnosis_agent_node(state)
                multi_agent_results["diagnosis"] = result.get("agent_result", result)
                
            elif agent_name == "security":
                result = await run_security_agent_node(state)
                multi_agent_results["security"] = result.get("agent_result", result)
                
            elif agent_name == "onboarding":
                result = await run_onboarding_agent_node(state)
                multi_agent_results["onboarding"] = result.get("agent_result", result)
                
            elif agent_name == "contributor":
                result = await run_contributor_agent_node(state)
                multi_agent_results["contributor"] = result.get("agent_result", result)
                
        except Exception as e:
            logger.error(f"Additional agent {agent_name} failed: {e}")
            multi_agent_results[agent_name] = {"error": str(e)}
    
    logger.info(f"Multi-agent execution completed: {list(multi_agent_results.keys())}")
    
    return {
        "multi_agent_results": multi_agent_results,
        "iteration": state.get("iteration", 0) + 1
    }


# === ê·¸ë˜í”„ ë¹Œë“œ ===

def build_supervisor_graph(enable_hitl: bool = False):
    """
    Supervisor Graph ë¹Œë“œ
    
    Args:
        enable_hitl: Human-in-the-Loop íŒ¨í„´ í™œì„±í™”.
                     Trueë©´ clarification_response ë…¸ë“œ ì „ì— ì¤‘ë‹¨.
    """
    
    graph = StateGraph(SupervisorState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("load_session", load_or_create_session_node)
    graph.add_node("parse_intent", parse_intent_node)
    graph.add_node("clarification_response", clarification_response_node)
    graph.add_node("run_diagnosis_agent", run_diagnosis_agent_node)
    graph.add_node("run_onboarding_agent", run_onboarding_agent_node)
    graph.add_node("run_security_agent", run_security_agent_node)
    graph.add_node("run_recommend_agent", run_recommend_agent_node)
    graph.add_node("run_contributor_agent", run_contributor_agent_node)
    graph.add_node("chat_response", chat_response_node)
    graph.add_node("finalize_answer", finalize_answer_node)
    graph.add_node("update_session", update_session_node)
    
    # ì—£ì§€ ì—°ê²°
    graph.set_entry_point("load_session")
    graph.add_edge("load_session", "parse_intent")
    
    # Clarification ì²´í¬ ë° Agent ë¼ìš°íŒ…
    def combined_routing(state: SupervisorState) -> Literal[
        "clarification_response", "run_diagnosis_agent", "run_onboarding_agent", 
        "run_security_agent", "run_recommend_agent", "run_contributor_agent", "chat_response"
    ]:
        """Clarification ì²´í¬ í›„ Agent ë¼ìš°íŒ…"""
        if state.get("needs_clarification", False):
            return "clarification_response"
        
        # Agent ë¼ìš°íŒ…
        target = state.get("target_agent")
        if not target:
            return "chat_response"
        
        if target == "diagnosis":
            return "run_diagnosis_agent"
        elif target == "onboarding":
            return "run_onboarding_agent"
        elif target == "security":
            return "run_security_agent"
        elif target == "recommend":
            return "run_recommend_agent"
        elif target == "contributor":
            return "run_contributor_agent"
        else:
            return "chat_response"
    
    graph.add_conditional_edges(
        "parse_intent",
        combined_routing,
        {
            "clarification_response": "clarification_response",
            "run_diagnosis_agent": "run_diagnosis_agent",
            "run_onboarding_agent": "run_onboarding_agent",
            "run_security_agent": "run_security_agent",
            "run_recommend_agent": "run_recommend_agent",
            "run_contributor_agent": "run_contributor_agent",
            "chat_response": "chat_response"
        }
    )
    
    # Clarification ì‘ë‹µ â†’ ì¢…ë£Œ
    graph.add_edge("clarification_response", "update_session")
    
    # ì¶”ê°€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ë…¸ë“œ
    graph.add_node("run_additional_agents", run_additional_agents_node)
    
    # ëª¨ë“  agent â†’ run_additional_agents â†’ finalize
    graph.add_edge("run_diagnosis_agent", "run_additional_agents")
    graph.add_edge("run_onboarding_agent", "run_additional_agents")
    graph.add_edge("run_security_agent", "run_additional_agents")
    graph.add_edge("run_recommend_agent", "run_additional_agents")
    graph.add_edge("run_contributor_agent", "run_additional_agents")
    graph.add_edge("run_additional_agents", "finalize_answer")
    graph.add_edge("chat_response", "update_session")
    
    # finalize â†’ update_session
    graph.add_edge("finalize_answer", "update_session")
    
    # update_session â†’ END
    graph.add_edge("update_session", END)
    
    return graph.compile(
        checkpointer=MemorySaver(),
        interrupt_before=["clarification_response"] if enable_hitl else None
    )


# === ì‹±ê¸€í†¤ ê·¸ë˜í”„ ===
_supervisor_graph = None

def get_supervisor_graph():
    """Supervisor Graph ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _supervisor_graph
    if _supervisor_graph is None:
        _supervisor_graph = build_supervisor_graph()
        logger.info("Supervisor Graph initialized")
    return _supervisor_graph


# === í¸ì˜ í•¨ìˆ˜ ===

async def run_supervisor(
    owner: str,
    repo: str,
    user_message: str,
    session_id: Optional[str] = None,
    ref: str = "main"
) -> Dict[str, Any]:
    """
    Supervisor ì‹¤í–‰
    
    Returns:
        {
            "session_id": "uuid",
            "final_answer": "...",
            "suggested_actions": [...],
            "awaiting_clarification": False
        }
    """
    
    graph = get_supervisor_graph()
    
    from typing import cast
    initial_state: SupervisorState = cast(SupervisorState, {
        "session_id": session_id,
        "owner": owner,
        "repo": repo,
        "ref": ref,
        "user_message": user_message,
        "is_new_session": False,
        "supervisor_intent": None,
        "needs_clarification": False,
        "clarification_questions": [],
        "awaiting_clarification": False,
        "conversation_history": [],
        "accumulated_context": {},
        "target_agent": None,
        "agent_params": {},
        "agent_result": None,
        "final_answer": None,
        "suggested_actions": [],
        "iteration": 0,
        "max_iterations": 10,
        "next_node_override": None,
        "error": None,
        "trace_id": None
    })
    
    final_state = await graph.ainvoke(initial_state)
    
    return {
        "session_id": final_state.get("session_id"),
        "final_answer": final_state.get("final_answer"),
        "suggested_actions": final_state.get("suggested_actions", []),
        "awaiting_clarification": final_state.get("awaiting_clarification", False),
        "target_agent": final_state.get("target_agent"),
        "agent_result": final_state.get("agent_result"),
        "needs_clarification": final_state.get("needs_clarification", False),
    }
