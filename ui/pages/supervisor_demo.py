"""
Supervisor Agent ë°ëª¨ í˜ì´ì§€

ìì—°ì–´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´:
1. ë¡œê·¸ ì¶•ì•½ë³¸ - ì—ì´ì „íŠ¸ íŒë‹¨ ê³¼ì •, ë„êµ¬ í˜¸ì¶œ ë‚´ì—­
2. ìµœì¢… ìš”ì•½ - LLMì´ ìƒì„±í•œ ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ
"""
from __future__ import annotations

import base64
import os
import sys
import time
import uuid
import logging
from typing import Any
from urllib.parse import quote

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

import streamlit as st

st.set_page_config(
    page_title="Supervisor Agent Demo",
    layout="wide",
)

# ë¡œê¹… ìº¡ì²˜ ì„¤ì •
class StreamlitLogHandler(logging.Handler):
    """Streamlitì— ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        super().__init__()
        self.logs = []
        
    def emit(self, record):
        try:
            msg = self.format(record)
            self.logs.append(msg)
            if len(self.logs) > 50:
                self.logs = self.logs[-50:]
        except Exception:
            pass
    
    def get_logs(self) -> list[str]:
        return self.logs.copy()


def capture_agent_logs():
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ë¡œê·¸ë¥¼ ìº¡ì²˜"""
    loggers = [
        "backend.agents.supervisor",
        "backend.agents.diagnosis",
        "backend.common",
    ]
    
    log_handler = StreamlitLogHandler()
    log_handler.setFormatter(logging.Formatter(
        "%(asctime)s | %(name)s | %(message)s",
        datefmt="%H:%M:%S"
    ))
    log_handler.setLevel(logging.INFO)
    
    for logger_name in loggers:
        logger = logging.getLogger(logger_name)
        logger.addHandler(log_handler)
        logger.setLevel(logging.INFO)
    
    return log_handler


# ê·¸ë˜í”„ ì‹œê°í™” í•¨ìˆ˜
def render_graph_visualization(result: dict | None):
    """Mermaid.ink APIë¡œ ê·¸ë˜í”„ë¥¼ PNG ì´ë¯¸ì§€ë¡œ ì‹œê°í™”"""
    if not result:
        st.caption("ì‹¤í–‰ ê²°ê³¼ ì—†ìŒ")
        return
    
    intent = result.get("intent", "")
    sub_intent = result.get("sub_intent", "")
    answer_kind = result.get("answer_kind", "chat")
    has_diagnosis = bool(result.get("diagnosis_result"))
    needs_disambiguation = result.get("_needs_disambiguation", False)
    
    # ì‹¤í–‰ëœ ê²½ë¡œ ê²°ì • (answer_kindê°€ disambiguationì´ë©´ ìš°ì„ )
    if needs_disambiguation or answer_kind == "disambiguation":
        path = "disambiguation"
    elif intent == "smalltalk" or intent == "help":
        path = "fast"
    elif intent == "overview":
        path = "overview"
    elif sub_intent in ("compare", "onepager"):
        path = "expert"
    elif has_diagnosis:
        path = "diagnosis"
    else:
        path = "summarize"
    
    # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
    mermaid_code = f'''flowchart TD
    subgraph Input
        START((Query))
    end
    
    subgraph Routing
        INIT[init]
        CLASSIFY[classify<br/>{intent}.{sub_intent}]
    end
    
    subgraph Processing
        DIAG[diagnosis]
        EXPERT[expert<br/>compare/onepager]
        FAST[fast path<br/>smalltalk/help]
    end
    
    subgraph Output
        SUMMARIZE[summarize]
        DISAMB[disambiguation]
        ANSWER((Answer<br/>{answer_kind}))
    end
    
    START --> INIT
    INIT --> CLASSIFY
'''
    
    # ê²½ë¡œë³„ í™”ì‚´í‘œ ì¶”ê°€
    if path == "fast":
        mermaid_code += '''
    CLASSIFY --> FAST
    FAST --> ANSWER
    style FAST fill:#4CAF50,stroke:#333,stroke-width:2px,color:#fff
'''
    elif path == "disambiguation":
        mermaid_code += '''
    CLASSIFY --> DISAMB
    DISAMB --> ANSWER
    style DISAMB fill:#FF9800,stroke:#333,stroke-width:2px,color:#fff
'''
    elif path == "expert":
        mermaid_code += '''
    CLASSIFY --> EXPERT
    EXPERT --> SUMMARIZE
    SUMMARIZE --> ANSWER
    style EXPERT fill:#4CAF50,stroke:#333,stroke-width:2px,color:#fff
'''
    elif path == "diagnosis":
        mermaid_code += '''
    CLASSIFY --> DIAG
    DIAG --> SUMMARIZE
    SUMMARIZE --> ANSWER
    style DIAG fill:#4CAF50,stroke:#333,stroke-width:2px,color:#fff
'''
    else:
        mermaid_code += '''
    CLASSIFY --> SUMMARIZE
    SUMMARIZE --> ANSWER
'''
    
    # ê³µí†µ ìŠ¤íƒ€ì¼
    mermaid_code += '''
    style START fill:#9C27B0,stroke:#333,stroke-width:2px,color:#fff
    style INIT fill:#2196F3,stroke:#333,stroke-width:2px,color:#fff
    style CLASSIFY fill:#2196F3,stroke:#333,stroke-width:2px,color:#fff
    style SUMMARIZE fill:#4CAF50,stroke:#333,stroke-width:2px,color:#fff
    style ANSWER fill:#E91E63,stroke:#333,stroke-width:2px,color:#fff
'''
    
    # Mermaid.ink APIë¡œ ì´ë¯¸ì§€ URL ìƒì„±
    mermaid_encoded = base64.urlsafe_b64encode(mermaid_code.encode()).decode()
    img_url = f"https://mermaid.ink/img/{mermaid_encoded}?bgColor=white"
    
    # í° ì´ë¯¸ì§€ë¡œ í‘œì‹œ
    st.image(img_url, caption="Supervisor Graph ì‹¤í–‰ ê²½ë¡œ", use_container_width=True)
    
    # ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
    col1, col2 = st.columns([1, 3])
    with col1:
        st.markdown(f"[PNG ë‹¤ìš´ë¡œë“œ]({img_url})")
    
    # ì‹¤í–‰ ê²½ë¡œ í…ìŠ¤íŠ¸ ì„¤ëª…
    path_desc = {
        "fast": "ê²½ëŸ‰ ê²½ë¡œ (LLM í˜¸ì¶œ ì—†ìŒ)",
        "disambiguation": "ì—”í‹°í‹° í™•ì¸ í•„ìš”",
        "expert": "ì „ë¬¸ ëŸ¬ë„ˆ ì‹¤í–‰",
        "diagnosis": "ì§„ë‹¨ ì—ì´ì „íŠ¸ ì‹¤í–‰",
        "overview": "ì €ì¥ì†Œ ê°œìš” ì¡°íšŒ",
        "summarize": "ì§ì ‘ ìš”ì•½",
    }
    with col2:
        st.caption(f"ì‹¤í–‰ ê²½ë¡œ: **{path_desc.get(path, path)}**")


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_result" not in st.session_state:
    st.session_state.last_result = None
if "analysis_history" not in st.session_state:
    # ë¶„ì„ëœ ì €ì¥ì†Œ ê²°ê³¼ë“¤ì„ ì €ì¥ (owner/repo -> result)
    st.session_state.analysis_history = {}
if "example_query" not in st.session_state:
    st.session_state.example_query = None
if "session_id" not in st.session_state:
    st.session_state.session_id = uuid.uuid4().hex
if "debug_events" not in st.session_state:
    st.session_state.debug_events = []  # ë””ë²„ê·¸ ì´ë²¤íŠ¸ ì €ì¥
if "turn_metrics" not in st.session_state:
    st.session_state.turn_metrics = []  # í„´ë³„ ë©”íŠ¸ë¦­ ì €ì¥


# ë©”ì¸ UI
st.title("Supervisor Agent Demo")
st.caption("ìì—°ì–´ë¡œ GitHub ì €ì¥ì†Œì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ì—ì´ì „íŠ¸ê°€ ë¶„ì„í•˜ê³  ì‘ë‹µí•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì •")
    
    show_log = st.checkbox("ì‹¤í–‰ ë¡œê·¸ í‘œì‹œ", value=True)
    show_scores = st.checkbox("ì ìˆ˜ ìƒì„¸ í‘œì‹œ", value=False)
    show_tasks = st.checkbox("ì˜¨ë³´ë”© Task í‘œì‹œ", value=False)
    debug_mode = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ", value=False, help="ì´ë²¤íŠ¸, ì—ëŸ¬, ì¬ê³„íš ì •ë³´ í‘œì‹œ")
    developer_mode = st.checkbox("ê°œë°œì ëª¨ë“œ", value=False, help="answer_kind, last_brief ë“± ë‚´ë¶€ ì •ë³´ í‘œì‹œ")
    show_metrics = st.checkbox("ìš´ì˜ ì§€í‘œ ëŒ€ì‹œë³´ë“œ", value=False, help="SLO, ë ˆì´í„´ì‹œ, ì—ëŸ¬ìœ¨ í‘œì‹œ")
    show_graph = st.checkbox("ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°í™”", value=False, help="ì‹¤í–‰ ê²½ë¡œ ë° ë…¸ë“œ ìƒíƒœ í‘œì‹œ")
    
    st.divider()
    
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.last_result = None
        st.session_state.analysis_history = {}
        if "example_query" in st.session_state:
            del st.session_state["example_query"]
        st.rerun()
    
    # ë¶„ì„ëœ ì €ì¥ì†Œ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    if st.session_state.analysis_history:
        st.divider()
        st.markdown("**ë¶„ì„ëœ ì €ì¥ì†Œ**")
        for repo_key in st.session_state.analysis_history.keys():
            st.caption(f"- {repo_key}")
    
    # ìš´ì˜ ì§€í‘œ ëŒ€ì‹œë³´ë“œ
    if show_metrics:
        st.divider()
        st.markdown("**ìš´ì˜ ì§€í‘œ**")
        
        turn_metrics = st.session_state.get("turn_metrics", [])
        if turn_metrics:
            # ìµœê·¼ 10ê°œ í„´ì˜ í‰ê·  ë©”íŠ¸ë¦­
            latencies = [m.get("latency_ms", 0) for m in turn_metrics[-10:]]
            avg_latency = sum(latencies) / len(latencies) if latencies else 0
            
            col_m1, col_m2 = st.columns(2)
            with col_m1:
                st.metric("í‰ê·  ë ˆì´í„´ì‹œ", f"{avg_latency:.0f}ms")
            with col_m2:
                success_count = sum(1 for m in turn_metrics if m.get("success", False))
                st.metric("ì„±ê³µë¥ ", f"{success_count}/{len(turn_metrics)}")
            
            # SLO ìƒíƒœ
            errors = [m for m in turn_metrics if m.get("error")]
            if errors:
                st.caption(f":red[ì—ëŸ¬ {len(errors)}ê±´]")
            else:
                st.caption(":green[SLO ì •ìƒ]")
        else:
            st.caption("ë°ì´í„° ì—†ìŒ")
    
    # ë””ë²„ê·¸ ì´ë²¤íŠ¸ ë·°ì–´
    if debug_mode:
        st.divider()
        st.markdown("**ë””ë²„ê·¸ ì´ë²¤íŠ¸**")
        
        debug_events = st.session_state.get("debug_events", [])
        if debug_events:
            for event in debug_events[-5:]:
                event_type = event.get("type", "unknown")
                if "error" in event_type.lower():
                    st.caption(f":red[{event_type}]")
                elif "retry" in event_type.lower() or "replan" in event_type.lower():
                    st.caption(f":orange[{event_type}]")
                else:
                    st.caption(f":gray[{event_type}]")
            
            if st.button("ì´ë²¤íŠ¸ ì´ˆê¸°í™”", key="clear_events"):
                st.session_state.debug_events = []
                st.rerun()
        else:
            st.caption("ì´ë²¤íŠ¸ ì—†ìŒ")
    
    # ë¹ ë¥¸ ë¬¸ì œ ì¶”ì  ì²´í¬ë¦¬ìŠ¤íŠ¸
    st.divider()
    st.markdown("**ë¹ ë¥¸ ë¬¸ì œ ì¶”ì **")
    
    last_result = st.session_state.get("last_result")
    if last_result:
        # 1. AnswerContract ê²€ì¦
        answer_contract = last_result.get("answer_contract", {})
        has_answer_contract = bool(answer_contract and answer_contract.get("text"))
        if has_answer_contract:
            st.caption(":green[1. AnswerContract ì •ìƒ]")
        else:
            st.caption(":red[1. AnswerContract ëˆ„ë½]")
        
        # 2. sources[] ê²€ì¦
        sources = answer_contract.get("sources", [])
        has_valid_sources = bool(sources and len(sources) > 0)
        if has_valid_sources:
            st.caption(f":green[2. sources: {len(sources)}ê°œ]")
        else:
            st.caption(":red[2. sources ë¹„ì–´ìˆìŒ]")
        
        # 3. ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ ê²€ì¦ (5ì¢…)
        debug_events = st.session_state.get("debug_events", [])
        event_types = [e.get("type", "") for e in debug_events[-10:]]
        required_events = ["init", "classify", "diagnosis", "summarize", "turn_complete"]
        found_events = sum(1 for req in required_events if any(req in et for et in event_types))
        if found_events >= 3:
            st.caption(f":green[3. ì´ë²¤íŠ¸ {found_events}/5ì¢…]")
        else:
            st.caption(f":orange[3. ì´ë²¤íŠ¸ {found_events}/5ì¢…]")
        
        # 4. ë¼ìš°íŒ… 2ë‹¨ê³„ ê²€ì¦
        classification_method = last_result.get("_classification_method", "unknown")
        if classification_method in ("heuristic", "llm"):
            st.caption(f":green[4. ë¼ìš°íŒ…: {classification_method}]")
        else:
            st.caption(f":orange[4. ë¼ìš°íŒ…: {classification_method}]")
        
        # 5. ëŸ¬ë„ˆ ì¶œë ¥ ê³„ì•½ ê²€ì¦
        expert_result = last_result.get("_expert_result")
        diagnosis_result = last_result.get("diagnosis_result")
        if expert_result or diagnosis_result:
            has_status = bool(expert_result and hasattr(expert_result, "success"))
            st.caption(f":green[5. ëŸ¬ë„ˆ ì¶œë ¥ ìˆìŒ]")
        else:
            # smalltalk/help ë“±ì€ ëŸ¬ë„ˆ ì—†ìŒ
            intent = last_result.get("intent", "")
            if intent in ("smalltalk", "help", "overview"):
                st.caption(f":gray[5. ëŸ¬ë„ˆ ë¶ˆí•„ìš” ({intent})]")
            else:
                st.caption(":orange[5. ëŸ¬ë„ˆ ì¶œë ¥ ì—†ìŒ]")
        
        # 6. ë””ê·¸ë ˆì´ë“œ/ì¬ê³„íš ë°œë™ ì—¬ë¶€
        errors = last_result.get("_errors", [])
        retries = last_result.get("_retries", [])
        needs_disambiguation = last_result.get("_needs_disambiguation", False)
        
        if errors or retries:
            st.caption(f":orange[6. ì¬ê³„íš: {len(retries)}íšŒ]")
        elif needs_disambiguation:
            st.caption(":orange[6. Disambiguation ë°œë™]")
        else:
            st.caption(":green[6. ì •ìƒ ê²½ë¡œ ì‹¤í–‰]")
        
        # ìƒì„¸ ë³´ê¸° ë²„íŠ¼
        with st.expander("ê²€ì¦ ìƒì„¸"):
            st.json({
                "has_answer_contract": has_answer_contract,
                "sources_count": len(sources),
                "sources_sample": sources[:3] if sources else [],
                "classification_method": classification_method,
                "intent": last_result.get("intent"),
                "sub_intent": last_result.get("sub_intent"),
                "answer_kind": last_result.get("answer_kind"),
                "needs_disambiguation": needs_disambiguation,
                "error_count": len(errors),
                "retry_count": len(retries),
            })
    else:
        st.caption(":gray[ê²°ê³¼ ì—†ìŒ - ë¨¼ì € ì§ˆë¬¸í•˜ì„¸ìš”]")
    
    # ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°í™”
    if show_graph:
        st.divider()
        st.markdown("**ê·¸ë˜í”„ êµ¬ì¡°**")
        render_graph_visualization(last_result)


# ì‘ë‹µ ìœ í˜• ë°°ì§€ í‘œì‹œ
ANSWER_KIND_BADGES = {
    "report": ("ì§„ë‹¨ ë¦¬í¬íŠ¸", "blue"),
    "explain": ("ì ìˆ˜ í•´ì„¤", "green"),
    "refine": ("Task í•„í„°ë§", "orange"),
    "concept": ("ê°œë… ì„¤ëª…", "violet"),
    "chat": ("ì¼ë°˜ ëŒ€í™”", "gray"),
    "greeting": ("ì¸ì‚¬", "gray"),
    "disambiguation": ("ì €ì¥ì†Œ ì„ íƒ", "red"),
    "compare": ("ë¹„êµ ë¶„ì„", "blue"),
    "onepager": ("ì›í˜ì´ì €", "blue"),
}


def get_answer_kind_badge(answer_kind: str) -> str:
    """answer_kindì— í•´ë‹¹í•˜ëŠ” Streamlit ë°°ì§€ ë§ˆí¬ë‹¤ìš´ ë°˜í™˜"""
    label, color = ANSWER_KIND_BADGES.get(answer_kind, ("ğŸ’¬ ì‘ë‹µ", "gray"))
    return f":{color}[{label}]"


# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
chat_container = st.container()

with chat_container:
    messages = st.session_state.messages
    total_msgs = len(messages)
    
    for idx, msg in enumerate(messages):
        is_last = (idx == total_msgs - 1)
        
        with st.chat_message(msg["role"]):
            # assistant ë©”ì‹œì§€ì— ë°°ì§€ í‘œì‹œ
            if msg["role"] == "assistant" and msg.get("metadata"):
                meta = msg["metadata"]
                answer_kind = meta.get("answer_kind", "chat")
                badge = get_answer_kind_badge(answer_kind)
                st.markdown(badge)
            
            # ì´ì „ ì‘ë‹µì€ ì ‘ê¸°ë¡œ í‘œì‹œ (ë§ˆì§€ë§‰ ì‘ë‹µ ì œì™¸)
            if msg["role"] == "assistant" and not is_last and msg["content"]:
                # ì´ì „ ì‘ë‹µì€ ì ‘ì–´ì„œ í‘œì‹œ
                content_preview = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
                with st.expander(f"ì´ì „ ì‘ë‹µ: {content_preview}", expanded=False):
                    st.markdown(msg["content"])
            else:
                st.markdown(msg["content"])
            
            # ë¡œê·¸/ìƒì„¸ì •ë³´ í‘œì‹œ (assistant ë©”ì‹œì§€ì—ë§Œ)
            if msg["role"] == "assistant" and msg.get("metadata"):
                meta = msg["metadata"]
                
                # ë©”íŠ¸ë¦­
                cols = st.columns(4)
                with cols[0]:
                    st.caption(f"ì‹¤í–‰ ì‹œê°„: {meta.get('elapsed', 'N/A')}")
                with cols[1]:
                    # intent â†’ sub_intent í‘œì‹œ (ìƒˆ êµ¬ì¡°)
                    intent_display = f"{meta.get('intent', 'N/A')}/{meta.get('sub_intent', 'N/A')}"
                    st.caption(f"Intent: {intent_display}")
                with cols[2]:
                    st.caption(f"Level: {meta.get('level', 'N/A')}")
                with cols[3]:
                    st.caption(f"Follow-up: {'ì˜ˆ' if meta.get('is_followup') else 'ì•„ë‹ˆì˜¤'}")
                
                # ê°œë°œì ëª¨ë“œ: last_brief í‘œì‹œ
                if developer_mode and meta.get("last_brief"):
                    with st.expander("last_brief (ë§¥ë½ ìš”ì•½)"):
                        st.caption(meta["last_brief"])
                
                # ë¡œê·¸
                if show_log and meta.get("log_summary"):
                    with st.expander("ì‹¤í–‰ ë¡œê·¸"):
                        st.markdown(meta["log_summary"])
                
                # ì ìˆ˜
                if show_scores and meta.get("scores") and isinstance(meta.get("scores"), dict):
                    with st.expander("ì ìˆ˜ ìƒì„¸"):
                        st.json(meta["scores"])
                
                # Task ëª©ë¡
                if show_tasks and meta.get("tasks") and isinstance(meta.get("tasks"), dict):
                    with st.expander("ì˜¨ë³´ë”© Task"):
                        for level_name, level_tasks in meta["tasks"].items():
                            if level_tasks and isinstance(level_tasks, list):
                                st.markdown(f"**{level_name.title()}** ({len(level_tasks)}ê°œ)")
                                for task in level_tasks[:3]:
                                    if isinstance(task, dict):
                                        st.markdown(f"- {task.get('title', 'N/A')}")


# ì±„íŒ… ì…ë ¥ (í•˜ë‹¨ ê³ ì •)
# ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ì—ì„œ ì„¤ì •í•œ ì¿¼ë¦¬ ì²˜ë¦¬
example_query = st.session_state.example_query
if example_query:
    st.session_state.example_query = None  # ë¦¬ì…‹
    prompt = example_query
else:
    prompt = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: facebook/react ìƒíƒœ ë¶„ì„í•´ì¤˜)")

if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({
        "role": "user",
        "content": prompt
    })
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with chat_container:
        with st.chat_message("user"):
            st.markdown(prompt)
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    from backend.agents.supervisor.graph import build_supervisor_graph
    from backend.common.events import get_event_store, EventType
    
    log_handler = capture_agent_logs()
    
    # ì´ë²¤íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
    captured_events = []
    def event_listener(event):
        captured_events.append({
            "type": event.type.value if hasattr(event.type, "value") else str(event.type),
            "actor": event.actor,
            "timestamp": event.timestamp,
            "inputs": event.inputs,
            "outputs": event.outputs,
        })
    
    event_store = get_event_store()
    event_store.add_listener(event_listener)
    
    with chat_container:
        with st.chat_message("assistant"):
            # ì§„í–‰ ìƒí™© í‘œì‹œ ì˜ì—­ (í•œ ì¤„ë§Œ ìœ ì§€, ë®ì–´ì“°ê¸°)
            status_placeholder = st.empty()
            start_time = time.time()
            
            def update_status(step: str, detail: str = ""):
                """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (í•œ ì¤„ë§Œ í‘œì‹œ)"""
                if detail:
                    status_placeholder.caption(f":gray[{step}: {detail}]")
                else:
                    status_placeholder.caption(f":gray[{step}]")
            
            try:
                graph = build_supervisor_graph()
                update_status("ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì¤‘", "Intent ë¶„ë¥˜...")
                
                # ì´ì „ ê²°ê³¼ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë©€í‹°í„´ ì§€ì›)
                initial_state = {
                    "user_query": prompt.strip(),
                    "history": [
                        {"role": m["role"], "content": m["content"]} 
                        for m in st.session_state.messages[:-1]
                    ],
                    # ì„¸ì…˜ ID ì „ë‹¬ (ì„¸ì…˜ ì—°ì†ì„± ë³´ì¥)
                    "_session_id": st.session_state.session_id,
                }
                
                # ì´ì „ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬ (Follow-up ì§€ì› ê°•í™”)
                if st.session_state.last_result:
                    prev = st.session_state.last_result
                    
                    # ì´ì „ ì €ì¥ì†Œ ì •ë³´ ì „ë‹¬
                    if prev.get("repo"):
                        initial_state["last_repo"] = prev.get("repo")
                    
                    # diagnosis_result ì§ì ‘ ì „ë‹¬ (Follow-up í•µì‹¬)
                    diag = prev.get("diagnosis_result")
                    if isinstance(diag, dict):
                        initial_state["diagnosis_result"] = diag
                        
                        # onboarding_tasksë¥¼ flat listë¡œ ë³€í™˜
                        onboarding_tasks = diag.get("onboarding_tasks", {})
                        task_list = []
                        for difficulty in ["beginner", "intermediate", "advanced"]:
                            for task in onboarding_tasks.get(difficulty, []):
                                task_copy = dict(task) if isinstance(task, dict) else {}
                                if "difficulty" not in task_copy:
                                    task_copy["difficulty"] = difficulty
                                task_list.append(task_copy)
                        initial_state["last_task_list"] = task_list
                    
                    # ì´ì „ answer_kind ì „ë‹¬ (Follow-up íƒ€ì… ê²°ì •)
                    if prev.get("answer_kind"):
                        initial_state["last_answer_kind"] = prev.get("answer_kind")
                    if prev.get("last_brief"):
                        initial_state["last_brief"] = prev.get("last_brief")
                    if prev.get("intent"):
                        initial_state["last_intent"] = prev.get("intent")
                
                # ë¶„ì„ íˆìŠ¤í† ë¦¬ ì „ë‹¬ (ì´ì „ì— ë¶„ì„í•œ ì €ì¥ì†Œë“¤)
                if st.session_state.analysis_history:
                    initial_state["analysis_history"] = st.session_state.analysis_history
                
                # ì§„í–‰ ìƒí™© ì½œë°± ì„¤ì •
                def progress_callback(step: str, detail: str = ""):
                    update_status(step, detail)
                
                initial_state["_progress_callback"] = progress_callback
                
                # ê·¸ë˜í”„ ì‹¤í–‰ (thread_idë¡œ ì„¸ì…˜ ìƒíƒœ ìœ ì§€)
                result = graph.invoke(
                    initial_state,
                    config={
                        "configurable": {
                            "thread_id": st.session_state.session_id,
                        }
                    },
                )
                elapsed = time.time() - start_time
                
                update_status("ì‘ë‹µ ìƒì„± ì™„ë£Œ", f"{elapsed:.1f}ì´ˆ")
                status_placeholder.empty()  # ì§„í–‰ ìƒí™© ì œê±°
                
                st.session_state.last_result = result
                
                # ë¶„ì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥ (ì €ì¥ì†Œë³„ë¡œ ê²°ê³¼ ìºì‹±)
                repo = result.get("repo")
                if repo and isinstance(repo, dict):
                    repo_key = f"{repo.get('owner')}/{repo.get('name')}"
                    st.session_state.analysis_history[repo_key] = {
                        "repo": repo,
                        "diagnosis": result.get("diagnosis_result"),
                        "task_type": result.get("task_type"),
                    }
                
                compare_repo = result.get("compare_repo")
                if compare_repo and isinstance(compare_repo, dict):
                    compare_key = f"{compare_repo.get('owner')}/{compare_repo.get('name')}"
                    compare_diag = result.get("compare_diagnosis_result")
                    if isinstance(compare_diag, dict):
                        st.session_state.analysis_history[compare_key] = {
                            "repo": compare_repo,
                            "diagnosis": compare_diag,
                            "task_type": result.get("task_type"),
                        }
                
                # ë°°ì§€ í‘œì‹œ (ì‘ë‹µ ìœ„ì—)
                answer_kind = result.get("answer_kind", "chat")
                badge = get_answer_kind_badge(answer_kind)
                st.markdown(badge)
                
                # ì‘ë‹µ í‘œì‹œ
                llm_summary = result.get("llm_summary", "")
                if llm_summary:
                    st.markdown(llm_summary)
                else:
                    st.warning("ì‘ë‹µì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                # ë¡œê·¸ ìš”ì•½ ìƒì„±
                log_lines = []
                log_lines.append(f"1. Intent ë¶„ë¥˜: `{result.get('task_type', 'N/A')}`")
                
                repo = result.get("repo")
                if repo:
                    log_lines.append(f"2. ì €ì¥ì†Œ: `{repo.get('owner')}/{repo.get('name')}`")
                
                compare_repo = result.get("compare_repo")
                if compare_repo:
                    log_lines.append(f"   ë¹„êµ ëŒ€ìƒ: `{compare_repo.get('owner')}/{compare_repo.get('name')}`")
                
                if result.get("is_followup"):
                    log_lines.append(f"3. Follow-up: `{result.get('followup_type', 'N/A')}`")
                
                diagnosis = result.get("diagnosis_result")
                if diagnosis and isinstance(diagnosis, dict):
                    scores = diagnosis.get("scores", {})
                    log_lines.append(f"4. Diagnosis ì™„ë£Œ")
                    log_lines.append(f"   - Health: `{scores.get('health_score', 'N/A')}`")
                
                compare_diagnosis = result.get("compare_diagnosis_result")
                if compare_diagnosis and isinstance(compare_diagnosis, dict):
                    compare_scores = compare_diagnosis.get("scores", {})
                    log_lines.append(f"5. ë¹„êµ ëŒ€ìƒ Health: `{compare_scores.get('health_score', 'N/A')}`")
                
                # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                user_ctx = result.get("user_context")
                level = user_ctx.get("level", "N/A") if isinstance(user_ctx, dict) else "N/A"
                
                metadata = {
                    "elapsed": f"{elapsed:.1f}ì´ˆ",
                    "intent": result.get("intent", result.get("task_type", "N/A")),
                    "sub_intent": result.get("sub_intent", "N/A"),
                    "answer_kind": result.get("answer_kind", "chat"),
                    "last_brief": result.get("last_brief", ""),
                    "level": level,
                    "is_followup": result.get("is_followup", False),
                    "log_summary": "\n".join(log_lines),
                    "scores": diagnosis.get("scores") if diagnosis and isinstance(diagnosis, dict) else None,
                    "tasks": diagnosis.get("onboarding_tasks") if diagnosis and isinstance(diagnosis, dict) else None,
                }
                
                # ë©”íŠ¸ë¦­ í‘œì‹œ
                cols = st.columns(4)
                with cols[0]:
                    st.caption(f"ì‹¤í–‰ ì‹œê°„: {metadata['elapsed']}")
                with cols[1]:
                    intent_display = f"{metadata['intent']}/{metadata['sub_intent']}"
                    st.caption(f"Intent: {intent_display}")
                with cols[2]:
                    st.caption(f"Level: {metadata['level']}")
                with cols[3]:
                    st.caption(f"Follow-up: {'ì˜ˆ' if metadata['is_followup'] else 'ì•„ë‹ˆì˜¤'}")
                
                # ê°œë°œì ëª¨ë“œ: last_brief í‘œì‹œ
                if developer_mode and metadata.get("last_brief"):
                    with st.expander("last_brief (ë§¥ë½ ìš”ì•½)"):
                        st.caption(metadata["last_brief"])
                
                # ë¡œê·¸ í‘œì‹œ
                if show_log:
                    with st.expander("ì‹¤í–‰ ë¡œê·¸"):
                        st.markdown(metadata["log_summary"])
                
                if show_scores and metadata.get("scores"):
                    with st.expander("ì ìˆ˜ ìƒì„¸"):
                        st.json(metadata["scores"])
                
                if show_tasks and metadata.get("tasks"):
                    with st.expander("ì˜¨ë³´ë”© Task"):
                        for level_name, level_tasks in metadata["tasks"].items():
                            if level_tasks and isinstance(level_tasks, list):
                                st.markdown(f"**{level_name.title()}** ({len(level_tasks)}ê°œ)")
                                for task in level_tasks[:3]:
                                    if isinstance(task, dict):
                                        st.markdown(f"- {task.get('title', 'N/A')}")
                
                # ë””ë²„ê·¸ ëª¨ë“œ: ì¶”ê°€ ì •ë³´ í‘œì‹œ
                if debug_mode:
                    with st.expander("ë””ë²„ê·¸ ì •ë³´"):
                        # Plan/Step ì •ë³´
                        plan_info = result.get("_plan_info", {})
                        if plan_info:
                            st.markdown("**Plan ì‹¤í–‰ ì •ë³´**")
                            st.json(plan_info)
                        
                        # ì—ëŸ¬/ì¬ì‹œë„ ì •ë³´
                        errors = result.get("_errors", [])
                        retries = result.get("_retries", [])
                        
                        if errors:
                            st.markdown("**ì—ëŸ¬ ë°œìƒ**")
                            for err in errors:
                                st.error(f"{err.get('type', 'unknown')}: {err.get('message', '')}")
                        
                        if retries:
                            st.markdown("**ì¬ì‹œë„ ì´ë ¥**")
                            for retry in retries:
                                st.warning(f"Step {retry.get('step_id')}: {retry.get('count')}íšŒ ì¬ì‹œë„")
                        
                        # answer_id (ì•„ì´ë¤í¬í„´ì‹œ)
                        answer_id = result.get("answer_id")
                        if answer_id:
                            st.caption(f"Answer ID: `{answer_id}`")
                        
                        # sources ê²€ì¦
                        sources = result.get("answer_contract", {}).get("sources", [])
                        if sources:
                            st.caption(f"Sources: {len(sources)}ê°œ")
                        else:
                            st.caption(":red[Sources: ì—†ìŒ (ê²€ì¦ ì‹¤íŒ¨)]")
                        
                        # ìº¡ì²˜ëœ ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸
                        if captured_events:
                            st.markdown("**ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸**")
                            for evt in captured_events:
                                evt_type = evt.get("type", "unknown")
                                evt_actor = evt.get("actor", "unknown")
                                st.caption(f"- `{evt_type}` ({evt_actor})")
                
                # ìº¡ì²˜ëœ ì´ë²¤íŠ¸ë¥¼ ë””ë²„ê·¸ ì´ë²¤íŠ¸ì— ì €ì¥
                for evt in captured_events:
                    st.session_state.debug_events.append({
                        "type": evt.get("type", "unknown"),
                        "actor": evt.get("actor", "unknown"),
                        "timestamp": evt.get("timestamp", time.time()),
                    })
                
                # í„´ ì™„ë£Œ ì´ë²¤íŠ¸ ì¶”ê°€
                st.session_state.debug_events.append({
                    "type": f"turn_complete:{metadata['intent']}/{metadata['sub_intent']}",
                    "timestamp": time.time(),
                    "latency_ms": elapsed * 1000,
                })
                
                # í„´ ë©”íŠ¸ë¦­ ì €ì¥
                st.session_state.turn_metrics.append({
                    "timestamp": time.time(),
                    "latency_ms": elapsed * 1000,
                    "intent": metadata["intent"],
                    "sub_intent": metadata["sub_intent"],
                    "success": True,
                    "error": None,
                })
                
                # ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": llm_summary,
                    "metadata": metadata
                })
                
            except Exception as e:
                status_placeholder.empty()
                error_str = str(e)
                elapsed_error = time.time() - start_time
                
                # GitHub NOT_FOUND ì˜¤ë¥˜ ì²˜ë¦¬
                if "NOT_FOUND" in error_str or "Could not resolve" in error_str:
                    # ì €ì¥ì†Œ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                    import re
                    repo_match = re.search(r"'([^']+/[^']+)'", error_str)
                    repo_name = repo_match.group(1) if repo_match else "ì…ë ¥í•œ ì €ì¥ì†Œ"
                    
                    error_msg = f"ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: `{repo_name}`\n\nì •í™•í•œ ì €ì¥ì†Œ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”. ì˜ˆ: `facebook/react`, `microsoft/vscode`"
                    st.warning(error_msg)
                    error_type = "not_found"
                elif "rate limit" in error_str.lower():
                    error_msg = "GitHub API ìš”ì²­ í•œë„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                    st.warning(error_msg)
                    error_type = "rate_limit"
                elif "timeout" in error_str.lower():
                    error_msg = "ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                    st.warning(error_msg)
                    error_type = "timeout"
                else:
                    error_msg = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
                    st.error(error_msg)
                    error_type = "unknown"
                
                # ë””ë²„ê·¸ ëª¨ë“œ: ìƒì„¸ ì—ëŸ¬ ì •ë³´
                if debug_mode:
                    import traceback
                    with st.expander("ì—ëŸ¬ ìƒì„¸ (ë””ë²„ê·¸)"):
                        st.code(traceback.format_exc())
                        st.caption(f"ì—ëŸ¬ ìœ í˜•: `{error_type}`")
                        st.caption(f"ì†Œìš” ì‹œê°„: `{elapsed_error:.2f}ì´ˆ`")
                    
                    # ë””ë²„ê·¸ ì´ë²¤íŠ¸ ì €ì¥
                    st.session_state.debug_events.append({
                        "type": f"error:{error_type}",
                        "timestamp": time.time(),
                        "message": error_str[:100],
                    })
                
                # í„´ ë©”íŠ¸ë¦­ ì €ì¥ (ì—ëŸ¬ í¬í•¨)
                st.session_state.turn_metrics.append({
                    "timestamp": time.time(),
                    "latency_ms": elapsed_error * 1000,
                    "intent": "unknown",
                    "sub_intent": "unknown",
                    "success": False,
                    "error": error_type,
                })
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg,
                    "metadata": {"error": error_type}
                })
            
            finally:
                # ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì •ë¦¬
                event_store.remove_listener(event_listener)
    
    st.rerun()
